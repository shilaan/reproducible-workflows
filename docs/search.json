[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Reproducible Workflows",
    "section": "",
    "text": "Introduction\nThis webpage contains a portfolio of some of the reproducible workflows I have generated as a Reproduction and Replication Analyst for the DARPA-SCORE Project (i.e., the Systematizing Confidence in Open Research and Evidence Project commissioned by the Defense Advanced Research Projects Agency) as well as my own research projects."
  },
  {
    "objectID": "score-political.html",
    "href": "score-political.html",
    "title": "1  SCORE Political Science",
    "section": "",
    "text": "# Install necessary R packages\ninstall.packages(\"here\") #for a project-based workflow\ninstall.packages(\"haven\")  #to read dta (Stata) file into R\ninstall.packages(\"tidyverse\") #for data processing\ninstall.packages(\"broom\") #for tidying the output of models\nremotes::install_github(\"crsh/papaja\") # for reporting of results\n\n\n# Load R packages\nlibrary(here) \nlibrary(haven)\nlibrary(tidyverse) \nlibrary(papaja)\nlibrary(broom)"
  },
  {
    "objectID": "score-political.html#read-data",
    "href": "score-political.html#read-data",
    "title": "1  SCORE Political Science",
    "section": "1.2 Read data",
    "text": "1.2 Read data\nThis document reports a re-analysis (as part of the SCORE Multi-100 Project) of the following paper:\nEinstein & Glick. (2016). Does Race Affect Access to Government Services? An Experiment Exploring Street-Level Bureaucrats and Access to Public Housing. American Journal of Political Science, 61(1), 100-116. https://doi.org/10.1111/ajps.12252\nThe Multi100 project is a crowdsourced empirical project aiming to estimate how robust published results and conclusions in social and behavioral sciences are to analysts’ analytical choices.\n\n# Read data (Stata) file into R\ndf &lt;- read_dta(\n  file = here(\"data/HousingAuditAJPSFinalPublic_Unidentified.dta\")\n  )"
  },
  {
    "objectID": "score-political.html#data-processing",
    "href": "score-political.html#data-processing",
    "title": "1  SCORE Political Science",
    "section": "1.3 Data processing",
    "text": "1.3 Data processing\nI investigate the Claim “Hispanic housing applicants were less likely to be greeted by name than were white counterparts.”\nThe binary indicator ProperName (0/1) indicates whether the email response began with any sort of named greeting. This is the dependent variable. Note: coded NA in case an email was not returned.\nThere are 6 treatment names, each representing a different treatment group. These are:\n\nNumberAssignment = 1: Black male named Tyrone\nNumberAssignment = 2: Black female named Shanice\nNumberAssignment = 3: Hispanic male named Santiago\nNumberAssignment = 4: Hispanic female named Gabriela\nNumberAssignment = 5: White male named Brett\nNumberAssignment = 6: White female named Emily\n\nTo compare Hispanic vs. White housing applicants only, I create a binary variable Hispanic_vs_White, with White applicants (Brett and Emily) coded as 0, Hispanic applicants (Santiago and Gabriela) coded as 1, and all other applicants coded as NA. This is the independent variable.\n\n# Create binary indicator for Hispanic vs. White housing applicants\ndf &lt;- df %&gt;% \n   mutate(\n     Hispanic_vs_White = case_when(\n       # Black applicants coded NA\n       NumberAssignment %in% 1:2 ~ NA_real_,\n       # Hispanic applicants coded 1\n       NumberAssignment %in% 3:4 ~ 1,\n       #White applicants coded 0\n       NumberAssignment %in% 5:6 ~ 0\n       ) \n     )"
  },
  {
    "objectID": "score-political.html#statistical-model",
    "href": "score-political.html#statistical-model",
    "title": "1  SCORE Political Science",
    "section": "1.4 Statistical model",
    "text": "1.4 Statistical model\nI will run a logistic regression model, to predict the log odds of being greeted by name from a binary indicator for Hispanic vs. White housing applicants. My (very simple) model is as follows:\n\\[\n\\text{logit}\\Big[\\pi(x)\\Big] = \\beta_0 + \\beta_1 x\n\\]\nWhere \\(\\pi(x)\\) stands for the success probability (i.e., probability of being greeted by name) as a function of \\(x\\), where \\(x\\) is a binary indicator (\\(x = 0\\) for White applicants; \\(x = 1\\) for Hispanic applicants).\nI test the following hypotheses: \\[\n\\begin{split}\nH_0&: \\beta_1 \\ge 0 \\\\\nH_1&: \\beta_1 &lt; 0\n\\end{split}\n\\]\nAfter running the logistic regression model, I will report the log odds of success, the odds of success, and the probabilities of success, for both Hispanic and White housing applicants.\n\\[\n\\begin{split}\n\\text{Log odds of success}&=\\begin{cases}\n\\beta_0 & ~~~~~~~~~~~~~~~~~~x = 0 \\text{ (White applicant)} \\\\\n\\beta_0 + \\beta_1 & ~~~~~~~~~~~~~~~~~~x =1 \\text{ (Hispanic applicant)} \\\\\n\\end{cases} \\\\\n\\text{Odds of success}&=\\begin{cases}\n\\exp(\\beta_0) & ~~~~~~~~~x = 0 \\\\\n\\exp(\\beta_0 + \\beta_1) & ~~~~~~~~~x =1 \\\\\n\\end{cases} \\\\\n\\text{Success probabilities}&=\\begin{cases}\n\\dfrac{\\exp(\\beta_0)}{1 + \\exp(\\beta_0)} & x = 0 \\\\\n\\dfrac{\\exp(\\beta_0 + \\beta_1)}{1 + \\exp(\\beta_0 + \\beta_1)} & x =1 \\\\\n\\end{cases}\n\\end{split}\n\\]"
  },
  {
    "objectID": "score-political.html#data-analysis",
    "href": "score-political.html#data-analysis",
    "title": "1  SCORE Political Science",
    "section": "1.5 Data analysis",
    "text": "1.5 Data analysis\n\n# Run logistic regression\nfit &lt;- glm(ProperName ~ Hispanic_vs_White, family = binomial, data = df)\n# Print tidy summary of model\ntidy(fit)\n\n# A tibble: 2 × 5\n  term              estimate std.error statistic  p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)          0.453     0.155      2.92 0.00347 \n2 Hispanic_vs_White   -0.810     0.215     -3.77 0.000162\n\n\nI find a negative effect for Hispanic housing applicants on the log odds of being greeted by name, \\(\\hat \\beta_1\\) \\(= -0.81\\), 95% CI \\([-1.23, -0.39]\\), \\(z = -3.77\\), \\(p &lt; .001\\). The estimated log odds of being greeted by name equal \\(\\hat \\beta_0 =\\) 0.45 for White applicants and \\(\\hat \\beta_0 + \\hat \\beta_1 =\\) -0.36 for Hispanic applicants. The estimated odds of being greeted by name equal \\(\\exp (\\hat\\beta_0) =\\) 1.57 for White housing applicants, and \\(\\exp(\\hat \\beta_0 + \\hat \\beta_1) =\\) 0.7 for Hispanic housing applicants. In other words, the estimated odds of being greeted by name are \\(1/\\exp (\\hat \\beta_1) \\approx\\) 2.25 times as high for White housing applicants than for Hispanic applicants.\nTranslating this to the estimated probabilities of being greeted by name, I find that the estimated probability of being greeted by name is 61% for White applicants; for Hispanic applicants, the estimated probability of being greeted by name is 41%. Thus, the probability of being greeted by name is 20 percentage points higher for White applicants than for Hispanic applicants.\n\n\n\n\n\n\n\n\nBeing greeted by name\nWhite applicants\nHispanic applicants\n\n\n\n\nLog odds\n\\(\\hat \\beta_0 =\\) 0.45\n\\(\\hat \\beta_0 + \\hat \\beta_1 =\\) -0.36\n\n\nOdds\n\\(\\exp (\\hat\\beta_0) =\\) 1.57\n\\(\\exp(\\hat \\beta_0 + \\hat \\beta_1) =\\) 0.7\n\n\nProbability (%)\n\\(\\text{Odds}/(1 + \\text{Odds})=\\) 61\n\\(\\text{Odds}/(1 + \\text{Odds})=\\) 41"
  },
  {
    "objectID": "score-political.html#reproducibility",
    "href": "score-political.html#reproducibility",
    "title": "1  SCORE Political Science",
    "section": "1.6 Reproducibility",
    "text": "1.6 Reproducibility\nNote that all of the reported results above are fully reproducible and were automatically generated with in-line R code. For example, the first result (\\(\\hat \\beta_1\\) \\(= -0.81\\), 95% CI \\([-1.23, -0.39]\\), \\(z = -3.77\\), \\(p &lt; .001\\)) can be generated as follows:\n\napa_print(fit)$full_result[2]\n\n$Hispanic_vs_White\n[1] \"$b = -0.81$, 95\\\\% CI $[-1.23, -0.39]$, $z = -3.77$, $p &lt; .001$\""
  },
  {
    "objectID": "score-meta.html",
    "href": "score-meta.html",
    "title": "2  SCORE Meta-Analysis",
    "section": "",
    "text": "Reproduction analyst: Shilaan Alzahawi\nSCORE RR ID: 24783\nOSF Project: https://osf.io/6mv2x/?view_only=d8c1abcd45eb483d8b8a39dc8b5058ab\nI did not deviate from the provided materials. All claims were successfully reproduced at the first attempt. To design the analysis, I consulted the following materials:"
  },
  {
    "objectID": "score-meta.html#reconstruction-of-data",
    "href": "score-meta.html#reconstruction-of-data",
    "title": "2  SCORE Meta-Analysis",
    "section": "2.1 Reconstruction of data",
    "text": "2.1 Reconstruction of data\nThe paper relies on four data sets:\n\nEffect sizes obtained from Vohs et al., 2006 and Caruso et al., 2013\nEffect sizes obtained from Klein et al., 2014 and Rohrer et al., 2015\nTable 1 in Vohs (2015)\nTable 2 in Vohs (2015)\n\nFootnote 1 describes deviations from the reported effect sizes.\n\n2.1.1 Vohs et al., 2006\n\nExperiment 1: “money prime versus control: t(49) = 2.44, p &lt; 0.02; Cohen’s d = 0.86”\nExperiment 2: “participants in the high-money condition worked significantly longer than participants in the low-money condition before asking for help [t(35) = 2.03, P= 0.05; Cohen’s d = 0.65; M high money = 1058.48 s, SD = 210.12; M low money = 876.63 s, SD = 334.42].”\nExperiment 3: “Participants in the money condition volunteered to help code fewer data sheets than did participants in the control condition [t(37) = 2.06, P &lt; 0.05; Cohen’s d = 0.66]”\nExperiment 4: “Participants who were primed with money were less helpful than participants not primed with money [t(42) = 2.13, P &lt; 0.04; Cohen’s d= 0.63].”\nExperiment 5: “Participants in the high-money condition gathered fewer pencils than did participants in the low-money condition [t(32) = 2.75, P &lt; 0.02; Cohen’s d = 0.81]”\nExperiment 6: “Participants primed with money donated significantly less money to the student fund than participants not primed with money [t(38) = 2.13, P &lt; 0.05; Cohen’s d = 0.64]”\nExperiment 7: “Participants primed with money placed the two chairs farther apart than did participants in the fish condition [t(33) = 2.37, P &lt; 0.05; Cohen’s d = 1.07]”\nExperiment 8: “money versus seascape: t(58) = 2.75, P &lt; 0.05; Cohen’s d = 0.59”\nExperiment 9: “Choosing to perform the task with a co-worker was reduced among money condition participants relative to participants in the fish [\\(\\chi^2\\)(1) = 7.00, P &lt; 0.05; odds ratio = 11.25] condition”. There were three conditions with 37 participants in total; I will assume that the number of participants in the two conditions of interest (money vs. fish) equals \\(37 \\cdot 2/3 \\approx 25\\).\n\nFor experiment 9, transform odds ratio to Cohen’s d using the following formula:\n\\[d = \\frac{\\ln(\\text{OR})}{\\pi / \\sqrt 3}\\]\n\n#Data obtained from Vohs, Mead, & Goode (2006)\nVohs_2006 &lt;- tibble(\n  Dataset = rep(\"Vohs, Mead, & Goode (2006)\"),\n  Study = as.character(1:9),\n  N = c(\n    51, \n    37,\n    39,\n    44,\n    34,\n    40,\n    35,\n    60,\n    25\n    ),\n  N1 = ceiling(N/2),\n  N2 = floor(N/2),\n  d = c(\n    0.86, \n    0.65,\n    0.66,\n    0.63,\n    0.81,\n    0.64,\n    1.07,\n    0.59,\n    log(11.25)/(pi/sqrt(3))\n    )\n) %&gt;% \n  select(!N)\n\n\n\n2.1.2 Caruso et al., 2013\n\nExperiment 1: “participants in the money condition more strongly endorsed system justification than did participants in the control condition, t(28) = 2.12, p = .043, d = 0.80”\nExperiment 2: “participants in the money condition reported stronger just-world beliefs than did participants in the control condition, t(166) = 2.81, p = .006, d = 0.44”\nExperiment 3: “participants in the money condition reported greater SDO than did participants in the control condition, t(78) = 2.24, p = .028, d = 0.51”\nExperiment 4: “Participants in the money prime condition reported significantly higher FMI (M = 0.65, SD = 0.98) than did those in the control condition (M = 0.37, SD = 1.03), F(1, 271) = 14.63, p &lt; .001”\nExperiment 5: “F(1, 88) = 5.84, p = .018”\n\n\n# Data obtained from Caruso et al., 2013\n\n#Function to get cohen's d for experiments 4 and 5\n#Obtained from Thalheimer, 2002\nget_d_from_f &lt;- function(f, n1, n2){\n  sqrt(f*((n1 + n2)/(n1 * n2))*((n1 + n2)/(n1 + n2 - 2)))\n}\n\nCaruso_2013 &lt;- tibble(\n  Dataset = rep(\"Caruso, Vohs, Baxter, & Waytz (2013)\"),\n  Study = as.character(1:5),\n  N = c(\n    30,\n    168,\n    80,\n    275,\n    92\n  ),\n  N1 = ceiling(N/2),\n  N2 = floor(N/2),\n  d = c(\n    0.80,\n    0.44,\n    0.51,\n    get_d_from_f(14.63, 138, 137),\n    get_d_from_f(5.84, 46, 46)\n  )\n) %&gt;% \n  select(!N)\n\n\n\n2.1.3 Klein et al., 2014\n\n36 sites: Ns for each site in Table 1\nThe original effect sizes are not in the paper: disaggregated data (Klein_2014.xlsx) obtained from https://osf.io/rn4ue/.\n\n\nKlein_ES &lt;- read_excel(\n  path = here(\"data/Klein_2014.xlsx\"), \n  sheet = \"Money Priming\"\n  )\n\n#Take out first two rows (Overall and Mean statistics)\nKlein_ES &lt;- Klein_ES[3:nrow(Klein_ES),]\n\n#Create clean dataframe for Klein et al. 2014\nKlein_2014 &lt;- tibble(\n  Dataset = rep(\"Klein et al. (2014)\"),\n  Study = as.character(1:36),\n  N1 = Klein_ES$`N (Money Priming)`,\n  N2 = Klein_ES$`N (Control)`,\n  d = Klein_ES$`ES (from means)`\n)\n\n\n\n2.1.4 Rohrer et al., 2015\n\nExperiment 1: N = 136, d = -0.07 (Table 1). “Each subject was randomly assigned to either the money condition (n = 69) or the control condition (n = 67).”\nExperiment 2: N = 420, d = 0.06 (Table 1). “Each subject was randomly assigned to either the money condition (n = 211) or the control condition (n = 209)”\nExperiment 3: N = 156, d = -0.06 (Table 1). “Each subject was randomly assigned to either the money condition (n = 78) or the control condition (n = 78).”\nExperiment 4: N = 116, d = 0.14 (Table 1). “Each subject was randomly assigned to either the money condition (n = 50 U.S. and 117 non-U.S.) or the control condition (n = 66 U.S. and 111 non-U.S.). The U.S. residents did not show a money priming effect, t(114) = 0.76, p = .46 (Table 1, Figure 3). The effect size (d) was 0.14”\nExperiment 2B: N = 212, d = 0 (Appendix F)\nExperiment 2C: N = 191, d = 0.23 (Appendix F). “assigned to either the money condition (n = 91) or the control condition (n = 100).”\n\n\nRohrer_2015 &lt;- tibble(\n  Dataset = rep(\"Rohrer, Pashler, & Harris (2015)\"),\n  Study = c(1:4, \"2B\", \"2C\"),\n  N1 = c(\n    69,\n    211,\n    78,\n    50,\n    91,\n    106\n    ),\n  N2 = c(\n    67,\n    209,\n    78,\n    66,\n    100,\n    106\n    ),\n  d = c(\n    -0.07,\n    0.06,\n    -0.06,\n    0.14,\n    0,\n    0.23\n    )\n) \n\n\n\n2.1.5 Vohs (2015) Table 1\nAll data obtained from Vohs (2015) Table 1: p. e88. Relevant information from Vadillo 2016:\n\n“Several of the effect sizes included in Tables 1 and 2 were not statistically independent (i.e., they referred to different dependent variables collected on the same participants). To avoid giving undue weight to nonindependent effect sizes, we included in our analyses only the first effect size from each study. However, to confirm that this decision did not make an important difference to our conclusions, the excluded effect sizes are shown …”\n\n\n# Data obtained from Vohs (2015) Table 1\nVohs_2015_T1 &lt;- tibble(\n  Dataset = rep(\"Vohs (2015) Table 1\"),\n  Study = c(\n    \"Aarts\",\n    \"Boucher Study 1\",\n    \"Boucher Study 2\",\n    \"Gasiorowska Study 1\",\n    \"Gasiorowska Study 1 Exclude\",\n    \"Gasiorowska Study 2\",\n    \"Mogilner Study 1\",\n    \"Mogilner Study 2\",\n    \"Mukherjee Study 2\",\n    \"Mukherjee Study 1\",\n    \"Mukherjee Study 2 Exclude\",\n    \"Park Study 3\",\n    \"Sarial-Abi Study 1\",\n    \"Sarial-Abi Study 1 Exclude\",\n    \"Sarial-Abi Study 1 Exclude\",\n    \"Sarial-Abi Study 2\",\n    \"Sarial-Abi Study 2 Exclude\",\n    \"Sarial-Abi Study 3\",\n    \"Sarial-Abi Study 3 Exclude\",     \n    \"Sarial-Abi Study 5\",\n    \"Sarial-Abi Study 5 Exclude\",\n    \"Sarial-Abi Study 5 Exclude\",\n    \"Teng Study 2\", \n    \"Teng Study 3\", \n    \"Teng Study 3 Exclude\", \n    \"Zhou Study 3\", \n    \"Zhou Study 4\" \n  ),\n  N = c(\n    40,\n    27,\n    21,\n    68,\n    68,\n    90,\n    212,\n    59,\n    88,\n    54,\n    36,\n    74,\n    54,\n    54,\n    54,\n    49,\n    49,\n    48,\n    48,\n    32,\n    32,\n    32,\n    36,\n    53,\n    53,\n    84,\n    96\n  ),\n  N1 = ceiling(N/2),\n  N2 = floor(N/2),\n  d = c(\n    0.85,\n    0.67,\n    1.13,\n    0.96,\n    1.14,\n    0.64,\n    0.31,\n    0.75,\n    0.46,\n    0.67,\n    0.63,\n    0.58,\n    1.24,\n    0.89,\n    0.94,\n    0.61,\n    0.63,\n    0.84,\n    0.65,\n    1.14,\n    1.72,\n    2.08,\n    0.74,\n    0.71,\n    0.59,\n    1.12,\n    0.57\n  )\n) %&gt;% \n  select(!N)\n\n\n\n2.1.6 Vohs (2015) Table 2\n\nRelevant information from Vadillo 2016: “During the review of the present article, an anonymous reviewer revealed that the data reported by Chatterjee, Rose, and Sinha (2013) are under investigation because several lines of evidence suggest that they are tainted (Pashler, Rohrer, Abramson, Wolfson, & Harris, 2016). Consequently, in our analysis we omitted two data points from this article that were originally included in Vohs’s tables.” This reproduction will also exclude the data points from Chatterjee et al. 2013.\nSimilar to Table 1, only the first effect size of each Study will be included.\nNB: I recoded the sign of the effect sizes in Table 2, such that positive effects are in the expected direction (in line with all other obtained data)\n\n\n#Data obtained from Vohs (2015) Table 2\nVohs_2015_T2 &lt;- tibble(\n  Dataset = rep(\"Vohs (2015) Table 2\"),\n  Study = c(\n    #Exclude the first two datapoints from Chatterjee\n    \"Gasiorowska Study 1\",\n    \"Gasiorowska Study 1 Exclude\", \n    \"Gasiorowska Study 1 Exclude\",\n    \"Gasiorowska Study 2\", \n    \"Gasiorowska Study 3a\", \n    \"Gasiorowska Study 3b\", \n    \"Gasiorowska Study 4\",\n    \"Gueguen Study 1\",\n    \"Gueguen Study 2\",\n    \"Kushlev Study 2\",\n    \"Kuzminska Study 3\",\n    \"Mogilner Study 1a\",\n    \"Mogilner Study 1a Exclude\",\n    \"Mogilner Study 2\",\n    \"Molinsky Study 1\",\n    \"Molinsky Study 1 Exclude\",\n    \"Molinsky Study 1 Exclude\",\n    \"Molinsky Study 1 Exclude\",\n    \"Molinsky Study 1 Exclude\",\n    \"Molinsky Study 2\",\n    \"Molinsky Study 2 Exclude\",\n    \"Molinsky Study 2 Exclude\",\n    \"Park Study 1\",\n    \"Park Study 1 Exclude\",\n    \"Park Study 2\",\n    \"Park Study 3\",\n    \"Pfeffer Study 2\",\n    \"Piers Study 1\",\n    \"Roberts Study 1\",\n    \"Roberts Study 1 Exclude\",\n    \"Teng Study 4\",\n    \"Xie Study 1\",\n    \"Xie Study 2\",\n    \"Xie Study 2 Exclude\"\n  ),\n  N = c(\n    67,\n    126,\n    126,\n    120,\n    129,\n    64,\n    84,\n    100,\n    50,\n    66,\n    74,\n    212,\n    212,\n    88,\n    rep(50, 5),\n    rep(80, 3),\n    rep(79, 2),\n    40,\n    74,\n    260,\n    208,\n    114,\n    114,\n    110,\n    94,\n    125,\n    126\n  ),\n  N1 = ceiling(N/2),\n  N2 = floor(N/2),\n  d = c(\n    0.49,\n    0.36,\n    0.63,\n    3.02,\n    1.24,\n    1.18,\n    1.05,\n    0.33,\n    0.25,\n    0.54,\n    0.59,\n    0.54,\n    0.38,\n    0.51,\n    0.58,\n    0.58,\n    -0.25,\n    0.64,\n    0.60,\n    0.50,\n    0.47,\n    0.51,\n    0.31,\n    0.37,\n    0.72,\n    0.35,\n    0.33,\n    0.29,\n    0.38,\n    0.36,\n    0.54,\n    0.66,\n    0.35,\n    0.52\n  )\n) %&gt;% \n  select(!N)"
  },
  {
    "objectID": "score-meta.html#create-final-dataset",
    "href": "score-meta.html#create-final-dataset",
    "title": "2  SCORE Meta-Analysis",
    "section": "2.2 Create final dataset",
    "text": "2.2 Create final dataset\n\ndf &lt;- bind_rows(\n  Vohs_2006, \n  Caruso_2013, \n  Klein_2014, \n  Rohrer_2015,\n  Vohs_2015_T1,\n  Vohs_2015_T2\n  ) %&gt;% \n  mutate(\n    Exclude = grepl(\"Exclude\", Study),\n    #Calculate SE\n    SE = sqrt((N1 + N2)/(N1*N2) + d^2/(2*(N1+N2))),\n    #Calculate x and y for Egger's regression test\n    #We predict the z score from 1/SE\n    z = d/SE, #z score\n    x = 1/SE,\n    #Separate the data into 5 groups as in Figure 1\n    group = factor(case_when(\n      Exclude ~ \"Excluded\",\n      Dataset %in% c(\n      \"Vohs, Mead, & Goode (2006)\", \"Caruso, Vohs, Baxter, & Waytz (2013)\"\n      ) ~ \"Vohs et al. (2006), Caruso et al. (2013)\",\n      Dataset == \"Vohs (2015) Table 1\" ~  \"Table 1 in Vohs (2015)\",\n      Dataset == \"Vohs (2015) Table 2\" ~ \"Table 2 in Vohs (2015)\",\n      TRUE ~ \"Klein et al. (2014), Rohrer et al. (2015)\"\n    ), \n    levels = c(\n      \"Vohs et al. (2006), Caruso et al. (2013)\",\n      \"Klein et al. (2014), Rohrer et al. (2015)\",\n      \"Table 1 in Vohs (2015)\",\n      \"Table 2 in Vohs (2015)\",\n      \"Excluded\"\n      )\n    ))"
  },
  {
    "objectID": "score-meta.html#claim-evaluations",
    "href": "score-meta.html#claim-evaluations",
    "title": "2  SCORE Meta-Analysis",
    "section": "2.3 Claim evaluations",
    "text": "2.3 Claim evaluations\n\nClaim 1Claim 2Claim 3Claim 4Claim 5Claim 6\n\n\nCoded claim text (original paper): The first set of effect sizes, represented by the darker circles (blue in the online version of the article), refers to the results of the seminal article on money priming (Vohs et al., 2006) and the original results of the study (Caruso et al., 2013) that Rohrer et al. (2015) attempted to replicate. As noted by Rohrer et al., visual inspection suggests that the effect sizes in this data set are strongly correlated with their standard errors. Egger’s regression test for funnel plot asymmetry (Egger et al., 1997) confirms that this relation is statistically significant, t(12) = 5.42, p &lt; .001.\nReproduction data source(s):\nhttps://osf.io/6mv2x/?view_only=d8c1abcd45eb483d8b8a39dc8b5058ab\nDescription of reproduction data:\nOriginal data obtained from original papers, accessed on March 4, 2022, accessible in the OSF project linked above: Vohs, Mead, & Goode (2006); Caruso, Vohs, Baxter, & Waytz (2013); Klein et al. (2014) with data posted at https://osf.io/rn4ue/; Rohrer, Pashler, & Harris (2015); Vohs (2015) Table 1 & Table 2. For Klein et al. (2014), disaggregated data was not included in the paper and was instead obtained from an OSF repository, accessed on March 5, 2022.\nPrimary reproduction criteria\n\n\n\n\n\n\n\n\n\n\nCriterion\nOriginal value\nPrecise reproduction\nApproximate reproduction\nNon-reproduction\n\n\n\n\nTest statistic\nt = 5.42\nt = 5.42\n4.61 \\(\\le\\) t \\(\\le\\) 6.23\nt &lt; 4.61 or t &gt; 6.23\n\n\np-value\np &lt; .001\np &lt; .001\n.001 \\(\\le\\) p \\(\\le\\) .051\np &gt; .051\n\n\n\nNB: The sample size and focal coefficient are considered “approximately reproduced” when the reproduction result is within 15% of the original result. For p-values, the result is considered “approximately reproduced” when it is within 0.05 points of the original.\nAnalyst success criteria: The claim will be considered reproducible if Egger’s regression test for funnel plot asymmetry meets the approximate reproduction criteria for the test statistic (4.61 \\(\\le\\) t \\(\\le\\) 6.23) and the precise reproduction criteria for the p-value (p &lt; .001).\nReproduction results\n\n#Extract results of Vohs et al., 2006 and Caruso et al., 2013\ndf_group1 &lt;- df %&gt;% \n  filter(group == \"Vohs et al. (2006), Caruso et al. (2013)\")\n\n#Run Egger's regression test\ntidy(lm(z ~ x, data = df_group1))[1, ]#we are interested in the intercept\n\n# A tibble: 1 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)     1.72     0.316      5.44 0.000150\n\n\nReproduction outcome: Based on the reproduction criteria, the claim did reproduce.\n\n\nCoded claim text (original paper): The two remaining data sets in Figure 1 refer to the effect sizes included in Vohs’s (2015) Tables 1 and 2. Regression tests confirmed that the remaining effect sizes were also related to their standard errors for the studies included in Table 2 (diamonds, which are purple in the online article), t(21) = 1.89, p = .072.\nReproduction data source(s):\nhttps://osf.io/6mv2x/?view_only=d8c1abcd45eb483d8b8a39dc8b5058ab\nDescription of reproduction data:\nOriginal data obtained from original papers, accessed on March 4, 2022, accessible in the OSF project linked above: Vohs, Mead, & Goode (2006); Caruso, Vohs, Baxter, & Waytz (2013); Klein et al. (2014) with data posted at https://osf.io/rn4ue/; Rohrer, Pashler, & Harris (2015); Vohs (2015) Table 1 & Table 2. For Klein et al. (2014), disaggregated data was not included in the paper and was instead obtained from an OSF repository, accessed on March 5, 2022.\nPrimary reproduction criteria\n\n\n\n\n\n\n\n\n\n\nCriterion\nOriginal value\nPrecise reproduction\nApproximate reproduction\nNon-reproduction\n\n\n\n\nTest statistic\nt = 1.89\nt = 1.89\n1.61 \\(\\le\\) t \\(\\le\\) 2.17\nt &lt; 1.61 or t &gt; 2.17\n\n\np-value\np = .072\np = .072\n.022 \\(\\le\\) p \\(\\le\\) .122\np &lt; .022 or p &gt; .122\n\n\n\nNB: The sample size and focal coefficient are considered “approximately reproduced” when the reproduction result is within 15% of the original result. For p-values, the result is considered “approximately reproduced” when it is within 0.05 points of the original.\nAnalyst success criteria: The claim will be considered reproducible if Egger’s regression test for funnel plot asymmetry meets the approximate reproduction criteria for the test statistic (1.61 \\(\\le\\) t \\(\\le\\) 2.17), and the p-value (.022 \\(\\le\\) p \\(\\le\\) .122).\nReproduction results\n\n#Extract results of Vohs (2015) Table 2\ndf_group2 &lt;- df %&gt;% \n  filter(Dataset == \"Vohs (2015) Table 2\" & !Exclude) \n\n#Run Egger's regression test\ntidy(lm(z ~ x, data = df_group2))[1, ]#we are again interested in the intercept\n\n# A tibble: 1 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)     3.49      1.94      1.80  0.0871\n\n\nReproduction outcome: Based on the reproduction criteria, the claim did reproduce.\n\n\nCoded claim text (original paper): Beyond the quantitative results of Egger’s regressions, perhaps the most remarkable feature of Figure 1 is that many of the effect sizes that reached statistical significance are packed together immediately adjacent to the gray contour representing statistical significance. Funnel plot asymmetry is not a perfect indicator of selection and reporting biases (Ioannidis, 2005; Sterne et al., 2011), but the close alignment of effect sizes with the border of significance makes it difficult to believe that this distribution of effect sizes is unbiased.\nReproduction data source(s):\nhttps://osf.io/6mv2x/?view_only=d8c1abcd45eb483d8b8a39dc8b5058ab\nDescription of reproduction data:\nOriginal data obtained from original papers, accessed on March 4, 2022, accessible in the OSF project linked above: Vohs, Mead, & Goode (2006); Caruso, Vohs, Baxter, & Waytz (2013); Klein et al. (2014) with data posted at https://osf.io/rn4ue/; Rohrer, Pashler, & Harris (2015); Vohs (2015) Table 1 & Table 2. For Klein et al. (2014), disaggregated data was not included in the paper and was instead obtained from an OSF repository, accessed on March 5, 2022.\nPrimary reproduction criteria\n\n\n\n\n\n\n\n\n\n\nCriterion\nOriginal value\nPrecise reproduction\nApproximate reproduction\nNon-reproduction\n\n\n\n\nSample size\nn = 99 effect sizes\nn = 99\n84 \\(\\le\\) n \\(\\le\\) 114\nn &lt; 84 or n &gt; 114\n\n\n\nNB: The sample size and focal coefficient are considered “approximately reproduced” when the reproduction result is within 15% of the original result. For p-values, the result is considered “approximately reproduced” when it is within 0.05 points of the original.\nAnalyst success criteria: The claim will be considered reproducible if a reproduction of Figure 1 will (1) meet the approximate reproduction criteria for sample size (85 \\(\\le\\) n \\(\\le\\) 144) and (2) lead to the same qualitative conclusion: a close alignment of effect sizes with the border of significance (i.e., statistically significant effects are packed together immediately adjacent to the grey contour representing statistical significance).\nReproduction results\n\n#calculate contours for the funnel plot\nSEs &lt;- seq(0.48, 0, length.out = nrow(df))\nlower_bounds_alpha1 &lt;- -qnorm(.05/2, lower.tail = F)*SEs\nupper_bounds_alpha1 &lt;- -lower_bounds_alpha1\nlower_bounds_alpha2 &lt;- -qnorm(.10/2, lower.tail = F)*SEs\nupper_bounds_alpha2 &lt;- -lower_bounds_alpha2\n\n#create contour-enhanced funnel plot\nfunnel_gww8qr &lt;- ggplot() +\n  #fill area for insignificant negative effects with p &gt; .10\n  geom_ribbon(\n    mapping = aes(xmin = 0, xmax = lower_bounds_alpha2, y = SEs),\n   fill = \"lightgray\", color = \"lightgray\",\n  ) +\n  scale_y_reverse(\n    limits = c(0.48, 0),\n    breaks = seq(0.4, 0, -0.1)\n  ) +\n  #fill area for insignificant positive effects with p &gt; .10\n  geom_ribbon( \n   mapping = aes(xmin = 0, xmax = upper_bounds_alpha2, y = SEs),\n   fill = \"lightgray\", color = \"lightgray\",\n  ) +\n  #fill area for marginally significant negative effects with .05 &lt; p &lt; .10\n  geom_ribbon( \n   mapping = aes(xmin = lower_bounds_alpha2, xmax = lower_bounds_alpha1, y = SEs),\n   fill = \"darkgray\", color = \"darkgray\",\n  ) +\n  #fill area for marginally significant positive effects with .05 &lt; p &lt; .10\n  geom_ribbon( \n   mapping = aes(xmin = upper_bounds_alpha2, xmax = upper_bounds_alpha1, y = SEs),\n   fill = \"darkgray\", color = \"darkgray\",\n  ) +\n  geom_point(\n    mapping = aes(\n      x = d, y = SE, color = group, shape = group, size = group\n      ),\n    data = df\n    ) +\n  theme_classic() +\n  scale_size_manual(\n    values = c(rep(2.5, 3), 3.5, 2.5)\n  ) +\n  scale_colour_manual(\n    values = c(\"blue\", \"darkgreen\", \"red\", \"purple\", \"orange\")\n    ) +\n  scale_shape_manual(\n    values = c(\"circle\", \"square\", \"triangle\", \"diamond\", \"circle\")\n  ) +\n  labs(x = \"Cohen's d\", y = \"Standard error\") +\n  scale_x_continuous(\n    breaks = 0:3,\n    labels = 0:3,\n    limits = c(-1, 3.2)\n  ) +\n  theme(\n    legend.title=element_blank(),\n    legend.position = c(0.8,0.85)\n    )\n\nfunnel_gww8qr\n\n\n\n#Check sample size\nnrow(df %&gt;% filter(group != \"Excluded\")) \n\n[1] 96\n\n\nReproduction outcome: Based on the reproduction criteria, the claim did reproduce.\n\n\nCoded claim text (original paper): Figure 2 represents the density function of z scores within these data sets. As can be seen, the modal z scores are just large enough to be statistically significant in a two-tailed test. This is also the case for the experiments reported by Vohs et al. (2006) and Caruso et al. (2013). [Figure 2, Vohs et al. (2006), Caruso et al. (2013)]\nReproduction data source(s):\nhttps://osf.io/6mv2x/?view_only=d8c1abcd45eb483d8b8a39dc8b5058ab\nDescription of reproduction data:\nOriginal data obtained from original papers, accessed on March 4, 2022, accessible in the OSF project linked above: Vohs, Mead, & Goode (2006); Caruso, Vohs, Baxter, & Waytz (2013); Klein et al. (2014) with data posted at https://osf.io/rn4ue/; Rohrer, Pashler, & Harris (2015); Vohs (2015) Table 1 & Table 2. For Klein et al. (2014), disaggregated data was not included in the paper and was instead obtained from an OSF repository, accessed on March 5, 2022.\nPrimary reproduction criteria\n\n\n\n\n\n\n\n\n\n\nCriterion\nOriginal value\nPrecise reproduction\nApproximate reproduction\nNon-reproduction\n\n\n\n\nSample size\nn = 116 effect sizes\nn = 116\n99 \\(\\le\\) n \\(\\le\\) 133\nn &lt; 99 or n &gt; 133\n\n\n\nNB: The sample size and focal coefficient are considered “approximately reproduced” when the reproduction result is within 15% of the original result. For p-values, the result is considered “approximately reproduced” when it is within 0.05 points of the original.\nAnalyst success criteria: The claim will be considered reproducible if a reproduction of Figure 2 will (1) meet the approximate reproduction criterion for sample size (99 \\(\\le\\) n \\(\\le\\) 134) and (2) lead to the same qualitative conclusion: the density function of the z scores for Vohs et al. (2006) and Caruso et al. (2013) peaks only slightly to the right of the vertical line that represents statistical significance (z = 1.96).\nReproduction results\n\n#Plot the density of the z scores\ndensity_gjvjlo &lt;- ggplot(\n  data = df, \n  mapping = aes(x = z, color = group, fill = group)\n  ) +\n  geom_density(alpha = 0.4) +\n  theme_classic() +\n  theme(\n    legend.title = element_blank(),\n    legend.position = c(0.8,0.85)\n  ) +\n  labs(x = \"z-scores\", y = \"Density\") +\n  scale_colour_manual(\n    values = c(\"blue\", \"darkgreen\", \"red\", \"purple\", \"orange\")\n    ) +\n  scale_fill_manual(\n    values = c(\"blue\", \"darkgreen\", \"red\", \"purple\", \"orange\")\n    ) +\n  scale_x_continuous(\n    limits = c(-2.5, 13)\n  ) +\n  geom_vline(xintercept = 1.64, linetype = \"dashed\") +\n  geom_vline(xintercept = 1.96, linetype = \"dashed\")\n\ndensity_gjvjlo\n\n\n\n#Check sample size\nnrow(df) \n\n[1] 117\n\n\nReproduction outcome: Based on the reproduction criteria, the claim did reproduce.\n\n\nCoded claim text (original paper): In Figure 3 we show the best fitting weight functions of two selection models (Dear & Begg, 1992) applied to the same four data sets that are included in Figure 1. As can be seen, both models suggest that p values play a crucial role in the distribution of effect sizes reported in Vohs et al. (2006) and Caruso et al. (2013), and in Tables 1 and 2 from Vohs (2015), but much less so in the Rohrer et al. (2015) and Klein et al. (2014) data. The best models of the former data sets are ones in which studies yielding p values greater than .1 are virtually guaranteed to be excluded…selection models yield nonflat weight functions when the proportion of nonsignificant results is implausibly low given the observed distribution of effect sizes and sample sizes. Thus, the weight functions depicted in Figure 3 show that a distribution of results like the one presented by Vohs is unlikely to have arisen in the absence of selection bias. [Figure 3, Dear & Begg, 1992]\nReproduction data source(s):\nhttps://osf.io/6mv2x/?view_only=d8c1abcd45eb483d8b8a39dc8b5058ab\nDescription of reproduction data:\nOriginal data obtained from original papers, accessed on March 4, 2022, accessible in the OSF project linked above: Vohs, Mead, & Goode (2006); Caruso, Vohs, Baxter, & Waytz (2013); Klein et al. (2014) with data posted at https://osf.io/rn4ue/; Rohrer, Pashler, & Harris (2015); Vohs (2015) Table 1 & Table 2. For Klein et al. (2014), disaggregated data was not included in the paper and was instead obtained from an OSF repository, accessed on March 5, 2022.\nPrimary reproduction criteria\n\n\n\n\n\n\n\n\n\n\nCriterion\nOriginal value\nPrecise reproduction\nApproximate reproduction\nNon-reproduction\n\n\n\n\nSample size\nn = 99 effect sizes\nn = 99\n84 \\(\\le\\) n \\(\\le\\) 114\nn &lt; 84 or n &gt; 114\n\n\n\nNB: The sample size and focal coefficient are considered “approximately reproduced” when the reproduction result is within 15% of the original result. For p-values, the result is considered “approximately reproduced” when it is within 0.05 points of the original.\nAnalyst success criteria: The claim will be considered reproducible if a reproduction of Figure 3 (top panel: Dear & Begg selection model) will (1) meet the approximate reproduction criterion for sample size (85 &lt; n &lt; 114, inclusive of endpoints) and (2) lead to the same qualitative conclusion: nonflat weight functions for the distribution of effect sizes reported in Vohs et al. (2006) and Caruso et al. (2013) and in Tables 1 and 2 from Vohs (2015), with the weights being highest for lower p-values (in particular, p &lt; .10), while the weight functions for Rohrer et al. (2015) and Klein et al. (2014) will be much less flat and will display less “bunching” at lower p-values.\nReproduction results\n\n#Fit Dear & Begg weight function\nweights &lt;- df %&gt;%\n  split(.$group) %&gt;%\n  map(~ DearBegg(y = .$d, u = .$SE, trace = FALSE))\n\nVohs &lt;- weights$`Vohs et al. (2006), Caruso et al. (2013)`\nKlein &lt;- weights$`Klein et al. (2014), Rohrer et al. (2015)`\nTable1 &lt;- weights$`Table 1 in Vohs (2015)`\nTable2 &lt;- weights$`Table 2 in Vohs (2015)`\n\n\n#Plot the best fitting weight function using the Dear & Begg selection model\nplot(0, 0, type = \"n\", xlim = c(0, 1), ylim = c(0, 1.66), xlab = \"p-values\",\n    ylab = \"Estimated weight function\")\nweightLine(Vohs$p, w = Vohs$w, col0 = \"blue\", lwd0 = 3)\nweightLine(Klein$p, w = Klein$w, col0 = \"darkgreen\", lwd0 = 4, lty0=2)\nweightLine(Table1$p, w = Table1$w, col0 = \"darkred\", lwd0 = 3)\nweightLine(Table2$p, w = Table2$w, col0 = \"purple\", lwd0 = 3)\nlegend(0.2, 1.66, legend = c(\n  \"Vohs et al. (2006), Caruso et al. (2013)\",\n  \"Klein et al. (2014), Rohrer et al. (2015)\",\n  \"Table 1 in Vohs (2015)\",\n  \"Table 2 in Vohs (2015)\"\n  ),\n  col = c(\"blue\", \"darkgreen\", \"darkred\", \"purple\"),\n  lty = c(1, 2, 1, 1),\n  lwd = 3\n  )\n\n\n\n\nReproduction outcome: Based on the reproduction criteria, the claim did reproduce.\n\n\nCoded claim text (original paper): The first row in our Table 1 shows the proportion of significant results reported in the four sets of studies. Indeed, their average power to detect an effect of the size estimated with a fixed-effect meta-analysis is only .55. The proportion of significant results (.86) is thus larger than the power estimates. [Table 1, Set of studies: Vohs et al. (2006); Caruso et al. (2013), Proportion of significant results = .86, Mean power to detect FE estimate = .55, p = .017, one-tailed, p &lt;.05]\nReproduction data source(s):\nhttps://osf.io/6mv2x/?view_only=d8c1abcd45eb483d8b8a39dc8b5058ab\nDescription of reproduction data:\nOriginal data obtained from original papers, accessed on March 4, 2022, accessible in the OSF project linked above: Vohs, Mead, & Goode (2006); Caruso, Vohs, Baxter, & Waytz (2013); Klein et al. (2014) with data posted at https://osf.io/rn4ue/; Rohrer, Pashler, & Harris (2015); Vohs (2015) Table 1 & Table 2. For Klein et al. (2014), disaggregated data was not included in the paper and was instead obtained from an OSF repository, accessed on March 5, 2022.\nReproduction criteria\n\n\n\n\n\n\n\n\n\n\nCriterion\nOriginal value\nPrecise reproduction\nApproximate reproduction\nNon-reproduction\n\n\n\n\np-value\np = .017\np = .017\np \\(\\le\\) .067\np &gt; .067\n\n\nProportion of significant results\nProp = .86\nProp = .86\n.73 \\(\\le\\) Prop \\(\\le\\) .99\nProp &lt; .73 or Prop &gt; .99\n\n\nMean power to detect FE estimate\nMean = .55\nMean = .55\n.47 \\(\\le\\) Mean \\(\\le\\) .63\nMean &lt; .47 or Mean &gt; .63\n\n\n\nNB: The sample size and focal coefficient are considered “approximately reproduced” when the reproduction result is within 15% of the original result. For p-values, the result is considered “approximately reproduced” when it is within 0.05 points of the original.\nAnalyst success criteria: The claim will be considered reproducible if a one-tailed binomial test contrasting the observed proportion of significant results with the probability of success given the estimate of power meets the approximate reproduction criteria outlined above for the p-value, proportion of significant results, and the mean power to detect the fixed effects estimate.\nReproduction results\n\n#Calculate proportion of significant results\nround(mean(Vohs$p &lt; 0.05), 2)\n\n[1] 0.93\n\n#Calculate meta-analytic effect size estimate\nd_meta &lt;- rma(yi = df_group1$d, sei = df_group1$SE, method = \"FE\")$b\n\n#For each study, calculate power to detect meta-analytic effect size estimate \ndf_group1 &lt;- df_group1 %&gt;% \n  rowwise() %&gt;% \n  mutate(\n    power = pwr.t2n.test(\n      n1 = N1, n2 = N2, d = d_meta, alternative = \"two.sided\")$power\n  )\n\n#Calculate average power across all studies\nround(mean(df_group1$power), 2)\n\n[1] 0.55\n\n#Calculate p value of one-tailed binomial test contrasting the observed \n#proportion of significant results with the probability of success given power\nbinom.test(\n  x = sum(Vohs$p &lt; .05), #number of successes\n  n = nrow(df_group1), #number of trials\n  p = mean(df_group1$power), #probability of success, based on power\n  alternative = \"greater\" #one-tailed test\n  )$p.value\n\n[1] 0.002979181\n\n\nReproduction outcome: Based on the reproduction criteria, the claim did reproduce."
  },
  {
    "objectID": "score-meta.html#description-of-materials-provided",
    "href": "score-meta.html#description-of-materials-provided",
    "title": "2  SCORE Meta-Analysis",
    "section": "2.4 Description of materials provided",
    "text": "2.4 Description of materials provided\nAll materials on the OSF project may be shared publicly. Overview and description of the materials:\n\nVadillo_JournExPsychGen_2016_BrGp_bushel_claims.md\nAn overview of all claims extracted from the paper\nVadillo_JournExPsychGen_2016_BrGp_24783_SDR_Pregistration.xlsx\nExcel workbook with the preregistered reproduction criteria for all claims part of the reproduction attempt\nOriginal papers from which data were obtained. All papers (except Vohs, 2015) are openly available online and added to the repository:\n\nCaruso 2013.pdf openly available at https://carlsonschool.umn.edu/sites/carlsonschool.umn.edu/files/2019-04/caruso_vohs_et_al_2013_jepg_0.pdf\nKlein et al (2014).pdf openly available at https://econtent.hogrefe.com/doi/10.1027/1864-9335/a000178\nRohrer 2015.pdf openly available at http://uweb.cas.usf.edu/~drohrer/pdfs/Rohrer_et_al_2015JEPG.pdf\nVohs 2006.pdf openly available at https://web.missouri.edu/~segerti/capstone/VohsMoney.pdf\n\nKlein_2014.xlsx\n\nData for Klein et al. 2014, obtained from https://osf.io/rn4ue/\n\nVadillo_2016.csv\nReconstructed dataset\nAnalysis-script.Rmd\nPreregistered analysis script (on randomly shuffled, blinded data)\nAnalysis-script.html\nKnitted output of the preregistered analysis script (on randomly shuffled, blinded data)\nTransparency Trail.Rmd\nTransparency trail of the reproduction attempt. This includes the analysis pipeline and full results/output of the analysis script (applied to the unblinded data)\nTransparency-Trail.html\nKnitted output of the transparency trail of the reproduction attempt. This includes the analysis pipeline and full results/output of the analysis script (applied to the unblinded data)"
  },
  {
    "objectID": "score-meta.html#references",
    "href": "score-meta.html#references",
    "title": "2  SCORE Meta-Analysis",
    "section": "2.5 References",
    "text": "2.5 References\nCaruso, Vohs, Baxter, & Waytz. (2013). Mere Exposure to Money Increases Endorsement of Free-Market Systems and Social Inequality. Journal of Experimental Psychology: General, 142(2), 301-306. https://doi.org/10.1037/a0029288\nKlein et al. (2014). Investigating Variation in Replicability: A “Many Labs” Replication Projects. Social Psychology, 45(3), 142-152. https://doi.org/10.1027/1864-9335/a000178\nRohrer, D., Pashler, H., & Harris, C.R. (2015). Do Subtle Reminders of Money Change People’s Political Views? Journal of Experimental Psychology: General, 144(4), e73-e85. http://dx.doi.org/10.1037/xge0000058\nThalheimer, W., & Cook, S. (2002, August). How to calculate effect sizes from published research articles: A simplified methodology. Retrieved March 4, 2022 from https://www.bwgriffin.com/gsu/courses/edur9131/content/Effect_Sizes_pdf5.pdf\nVadillo, Hardwicke, & Shanks. (2016). Selection Bias, Vote Counting, and Money-Priming Effects: A Comment on Rohrer, Pashler, and Harris (2015) and Vohs (2015). Journal of Experimental Psychology: General, 145(5), 655-663. https://doi.org/10.1037/xge0000157\nVohs, Mead, & Goode. (2006). The Psychological Consequences of Money. Science, 314(5802), 1154-1156. https://psycnet.apa.org/doi/10.1126/science.1132491\nVohs. (2015). Money Priming Can Change People’s Thoughts, Feelings, Motivations, and Behaviors: An Update on 10 Years of Experiments. Journal of Experimental Psychology: General, 144(4), e86-e93. http://dx.doi.org/10.1037/xge0000091"
  },
  {
    "objectID": "score-criminology.html",
    "href": "score-criminology.html",
    "title": "3  SCORE Criminology",
    "section": "",
    "text": "Reproduction analyst(s): Shilaan Alzahawi\nSCORE RR ID: 2w9mo\nOSF Project: https://osf.io/3j7gq/?view_only=b0e33287a13146d1a2d9c4ad938be094\nI did not deviate from the provided materials. All claims were successfully reproduced at the first attempt. To design the analysis, I consulted the following materials:"
  },
  {
    "objectID": "score-criminology.html#read-data",
    "href": "score-criminology.html#read-data",
    "title": "3  SCORE Criminology",
    "section": "3.1 Read data",
    "text": "3.1 Read data\n\n#Data obtained from the NLS here https://www.bls.gov/nls/nlsy97.htm \nNLSY97 &lt;- read.table(here(\"data/NLSY97.dat\"), sep = \" \")\n\n#Run helper functions obtained from the NLS\nsource(here(\"code/NLSY97-helper-functions.R\"))\n\n#Rename variables using Question names instead of Reference Numbers\nNLSY97 &lt;- qnames(NLSY97)"
  },
  {
    "objectID": "score-criminology.html#data-cleaning-and-processing",
    "href": "score-criminology.html#data-cleaning-and-processing",
    "title": "3  SCORE Criminology",
    "section": "3.2 Data cleaning and processing",
    "text": "3.2 Data cleaning and processing\n\n3.2.1 Incarceration data\n\n#Get incarceration data\nincarceration &lt;- NLSY97 %&gt;% \n  select(contains(\"INCARC\"))\n\n#Calculate the total number of months respondents were incarcerated\nmonths_incarcerated &lt;- rowSums(incarceration, na.rm = TRUE)\n\n\n\n3.2.2 Age\n\n#Age at start of survey\nage &lt;- NLSY97$`CV_AGE_12/31/96_1997`\n\n#Calculate age for each respondent at each timepoint (156 timepoints in total)\nages &lt;- 1:nrow(NLSY97) %&gt;% \n  #Sequence from age at t=1 to 13 years later\n  map(~ seq(age[.x], age[.x] + 13, length.out = 156)) %&gt;% \n  unlist()\n\n#Create dataframe with respondent id and age over time\nall_ages &lt;- tibble(\n  id = rep(1:nrow(NLSY97), each = 156),\n  age = ages\n)\n\n\n\n3.2.3 Create initial dataset\n\n#Create clean dataframe with relevant variables\ndf &lt;- tibble(\n  #respondent id\n  id = 1:nrow(NLSY97),\n  #gender: 1 = male\n  male = ifelse(NLSY97$KEY_SEX_1997 == 2, 0, 1),\n  #race: 1 = black\n  black = ifelse(NLSY97$KEY_RACE_ETHNICITY_1997 == 1, 1, 0),\n  #household size: number of individuals below 18\n  household_size = NLSY97$CV_HH_UNDER_18_1997,\n  #family structure: 1 = intact\n  family_structure = ifelse(NLSY97$CV_YTH_REL_HH_CURRENT_1997 == 1, 1, 0),\n  #lack of heat: 1 = home lacked electricity and heat in previous month\n  lack_heat = ifelse(NLSY97$`YSAQ-003_1997` == 0, 1, 0),\n  #hard times\n  hard_times = NLSY97$`PC8-090_1997`,\n  #presence of dilapidated buildings: 1 = poorly kept buildings\n  dilapidated = ifelse(NLSY97$`YIR-1400_1998` == 3, 1, 0),\n  #education of parents\n  education_mother = NLSY97$CV_HGC_BIO_MOM_1997,\n  education_father = NLSY97$CV_HGC_BIO_DAD_1997,\n  #age of first sexual intercourse: 1 = at or before 13 years of age\n  age_sex = ifelse(NLSY97$`YSAQ-300_1999` &lt; 14, 1, 0),\n  #age of first arrest: 1 = at or before 13 years of age\n  age_arrest = ifelse(NLSY97$`YSAQ-441_1997` &lt; 14, 1, 0),\n  #age of first weed use: 1 = at or before 13 years of age\n  age_weed = ifelse(NLSY97$`YSAQ-370_1997` &lt; 14, 1, 0),\n  #age of first cocaine use: 1 = at or before 13 years of age\n  age_cocaine = ifelse(NLSY97$`YSAQ-372C_1998` &lt; 14, 1, 0),\n  #incarcerated: 1 = at least one episode of incarceration\n  incarcerated = ifelse(months_incarcerated &gt; 0, 1, 0)\n) %&gt;% \n  rowwise() %&gt;% \n  mutate(\n  #disadvantaged = 1 if lack_heat or hard_times or dilapidated buildings\n  disadvantage = ifelse(\n    sum(lack_heat, hard_times, dilapidated, na.rm = TRUE) &gt; 0, 1, 0\n    ),\n  #mean parental education\n  parental_education = mean(c(education_mother, education_father), na.rm = TRUE),\n  #drug use = 1 if used weed or cocaine before 14 years of age\n  age_drug = ifelse(sum(age_weed, age_cocaine, na.rm = TRUE) &gt; 0, 1, 0),\n  #at risk = sum of age_sex, age_drug, age_arrest\n  at_risk = sum(age_sex, age_drug, age_arrest, na.rm = TRUE)\n  ) %&gt;% \n  #keep relevant variables\n  select(\n    id:family_structure, \n    disadvantage:parental_education, \n    at_risk, \n    incarcerated\n    )\n\n\n\n3.2.4 Arrest status\nArrest status is collected every month, with the following answer options:\n\n0: R not arrested in this month and not arrested in a previous month\n1 to 98: Number of times R arrested in this month\n99: R arrested previously but not in this month\n\nThe authors recode this to a binary, monthly arrest status variable: nonevent months are coded 0, whereas months with at least one documented arrest are coded 1.\n\narrest &lt;- NLSY97 %&gt;% \n  #select relevant columns\n  select(contains(\"ARREST\")) %&gt;% \n  #create participant id\n  mutate(\n    id = 1:nrow(NLSY97)\n  ) %&gt;% \n  #make data long: each time point becomes an individual row\n  pivot_longer(\n    cols = contains(\"ARREST\"),\n    names_to = \"time\",\n    names_pattern = \"ARREST_STATUS_?(.*)_XRND\",\n    values_to = \"arrest\"\n  ) %&gt;% \n  group_by(id) %&gt;% \n  #calculate the total number of arrests for each respondent\n  mutate(\n    sum_arrests = sum(arrest, na.rm = TRUE)\n  ) %&gt;% \n  ungroup() %&gt;% \n  #keep only respondents who were arrested at least once\n  filter(sum_arrests &gt; 0) %&gt;% \n  #recode arrest to binary indicator variable\n  mutate(\n    arrest = ifelse(arrest %in% c(0,99), 0, ifelse(is.na(arrest), NA, 1))\n  ) %&gt;% \n  select(!sum_arrests)\n\n#data quality checks\n#for each respondent, we should have 156 rows (13 years * 12 months) \n#number_of_timepoints &lt;- ncol(NLSY97 %&gt;% select(contains(\"ARREST\")))\n#number_of_respondents &lt;- length(unique(arrest$id)) #in paper: 2,959 (Table 2)\n#nrow(arrest) == number_of_respondents * number_of_timepoints #TRUE\n\n\n\n3.2.5 Relationship status\nRelationship status is collected every month, with the following answer options:\n\n0 Never Married, Not Cohabitating\n1 Never Married, Cohabiting\n2 Married\n3 Legally Separated\n4 Divorced\n5 Widowed\n\nThe authors create separate, mutually exclusive relationship indicators:\n\nSingle\nMarried\nLegally separated\nDivorced\n\nIt is unclear what the authors do with widowers.\n\nmarital &lt;- NLSY97 %&gt;% \n  #select relevant columns\n  select(contains(\"MAR\")) %&gt;% \n  #create participant id\n  mutate(\n    id = 1:nrow(NLSY97)\n  ) %&gt;% \n  #make data long: each time point becomes an individual row\n  pivot_longer(\n    cols = contains(\"MAR\"),\n    names_to = \"time\",\n    names_pattern = \"MAR_STATUS_?(.*)_XRND\",\n    values_to = \"marital_status\"\n  ) %&gt;%\n  #create indicator variables for relationship status\n  mutate(\n    #note that the paper does not disclose what to do with widowers\n    married = ifelse(marital_status == 2, 1, 0),\n    divorced = ifelse(marital_status == 4, 1, 0),\n    separated = ifelse(marital_status == 3, 1, 0),\n    single = ifelse(marital_status %in% c(0, 1), 1, 0)\n  ) %&gt;% \n  group_by(id) %&gt;% \n  #calculate the total number of months of marriage per respondent\n  mutate(\n    months_married = sum(married, na.rm = TRUE)\n  ) %&gt;% \n  ungroup() %&gt;% \n  #only keep respondents who were married for at least 1 month \n  filter(months_married &gt; 0) %&gt;% \n  select(!marital_status)\n\n#data quality checks\n#for each respondent, we should have 156 rows (13 years * 12 months) \n#number_of_timepoints &lt;- ncol(NLSY97 %&gt;% select(contains(\"MAR\")))\n#number_of_respondents &lt;- length(unique(marital$id)) #in paper: 2,848 (Table 2)\n#nrow(marital) == number_of_respondents * number_of_timepoints #TRUE\n#\"a third of the full sample has ever married by 2009:\"\n#number_of_respondents / nrow(NLSY97) #35 percent\n#mean number of months married in paper is 47.86\n#mean(marital$months_married) #48.73 months\n#for those who have ever been married, marriage length is an average of 4 years\n#mean(marital$months_married) /12 #4.06 years\n#all data quality checks passed"
  },
  {
    "objectID": "score-criminology.html#create-final-merged-dataset",
    "href": "score-criminology.html#create-final-merged-dataset",
    "title": "3  SCORE Criminology",
    "section": "3.3 Create final, merged dataset",
    "text": "3.3 Create final, merged dataset\n\n#keep only the marriage data for respondents who were ever arrested\nmarital &lt;- marital %&gt;% \n  filter(id %in% arrest$id)\n\n#keep only the arrest data for respondents who were ever married\narrest &lt;- arrest %&gt;% \n  filter(id %in% marital$id)\n\n#keep only age data for respondent who were ever arrested and ever married\nall_ages &lt;- all_ages %&gt;% \n  filter(id %in% arrest$id)\n \n#create final dataframe (long) with marriage data, arrest data, and covariates\ndf_long &lt;- left_join(marital, df, by = \"id\") %&gt;% \n  left_join(arrest, by = c(\"id\", \"time\")) %&gt;% \n  mutate(\n    id = factor(id),\n    age = all_ages$age,\n    age_sq = age^2\n  ) %&gt;%\n  group_by(id) %&gt;%\n  mutate(\n    #mean relationship state for each individual (between-individual control)\n    married_mean = mean(married, na.rm = TRUE),\n    divorced_mean = mean(divorced, na.rm = TRUE),\n    separated_mean = mean(separated, na.rm = TRUE),\n    single_mean = mean(single, na.rm = TRUE)\n  )\n\n#data quality check: n=813 in paper\n#nlevels(df_long$id) #n=882"
  },
  {
    "objectID": "score-criminology.html#statistical-model",
    "href": "score-criminology.html#statistical-model",
    "title": "3  SCORE Criminology",
    "section": "3.4 Statistical model",
    "text": "3.4 Statistical model\nInformation obtained from paper:\n\nGeneralized Mixed Model (binomial family with logit link)\nEstimates obtained using penalized quasi-likelihood estimation (PQL)\nDependent variable: arrest status (log odds of arrest)\nTime-varying covariates: relationship status (single, marriage, legal separation, divorce), age, and age squared\nTime-invariant covariates: gender, race, household size, family structure, disadvantage, parental education, at-risk, incarceration history\nLevel-1 (‘within’) variables: relationship state, age, and age\\(^2\\)\nLevel-2 (‘between’) variables: aggregate relationship state, controls\n\n\nlibrary(MASS)\nlongest_marriage &lt;- max(df_long$months_married)\n\n#Function to run the statistical model for a given number of months married\nrun_model &lt;- function(months = 1:longest_marriage) {\n  #run a generalized mixed model (binomial with logit link)\n  glmmPQL( #using penalized quasi-likelihood (PQL) estimation\n    #regress arrest on within-individual and between-individual predictors\n  fixed = arrest ~ \n    #within-individual, time-varying predictors\n    divorced + separated + single + age + age_sq +\n    #between-individual, time-stable predictors\n    divorced_mean + separated_mean + single_mean + \n    male + black + household_size + family_structure + disadvantage + \n    parental_education + at_risk + incarcerated, \n  random = ~ 1 | id, #each individual is a cluster with 156 timepoints\n  family = binomial, #we're predicting the log odds of arrest\n  data = df_long %&gt;% filter(months_married %in% months),\n  verbose = FALSE\n  )\n}"
  },
  {
    "objectID": "score-criminology.html#claim-evaluations",
    "href": "score-criminology.html#claim-evaluations",
    "title": "3  SCORE Criminology",
    "section": "3.5 Claim evaluations",
    "text": "3.5 Claim evaluations\nBushel claims obtained from the OSF here.\n\nClaim 1Claim 2: Model 1Claim 2: Model 2Claim 2: Model 3Claim 2: Model 4\n\n\nCoded claim text (original paper): Divorce has a significant detrimental effect on offending and increases the likelihood of arrest by 52 percent (table 3, model 2). Stated simply, an individual is more criminally active when divorced compared with when he or she is married, taking into account periods of legal separation and time single.\n[Table 3, Within Individual: Divorce, Model 2, Coeff. = .418, SE = .093, Sig. = p &lt; .001]\nReproduction data source(s):\nhttps://www.nlsinfo.org/investigator/pages/search#\nDescription of reproduction data:\nOriginal data obtained from the US Bureau of Labor Statistics. NLSY97 (National Longitudinal Study of Youth 1997) downloaded from the NLS investigator on March 1, 2022.\nReproduction criteria\n\n\n\n\n\n\n\n\n\n\nCriterion\nOriginal value\nPrecise reproduction\nApproximate reproduction\nNon-reproduction\n\n\n\n\nSample size\nn = 813\nn = 813\n691 \\(\\le\\) n \\(\\le\\) 935\nn &lt; 691 or n &gt; 935\n\n\nCoefficient\n\\(\\beta\\) = .418\n\\(\\beta\\) = .418\n.355 \\(\\le \\beta \\le\\) .481\n\\(\\beta\\) &lt; .355 or \\(\\beta\\) &gt; .481\n\n\np-value\np &lt; .001\np &lt; .001\n.001 \\(\\le\\) p \\(\\le\\) .051\np &gt; .051\n\n\n\nNB: The sample size and focal coefficient are considered “approximately reproduced” when the reproduction result is within 15% of the original result. For p-values, the result is considered “approximately reproduced” when it is within 0.05 points of the original.\nAnalyst success criteria: The claim will be considered reproducible if a generalized mixed model predicting the log odds of arrest meets the approximate reproduction criteria for the sample size, p-value, and the focal coefficient of divorce.\nReproduction results\n\nclaim1 &lt;- run_model() #run model on entire sample\n#check fixed effect of divorce\nsummary(claim1)$tTable[\"divorced\", c(\"Value\", \"p-value\")]\n\n        Value       p-value \n0.47692474621 0.00008120623 \n\nclaim1$dims$ngrps[1] #check sample size\n\n id \n826 \n\n\nReproduction outcome: Based on the reproduction criteria, the claim did reproduce.\n\n\nCoded claim text (original paper): For short marriages, those lasting 23 months or less (models 1 and 2), neither getting divorced nor legally separating statistically alters one’s risk of arrest compared with when they were married. Conversely, for those in marriages lasting 24 months or longer, divorce is associated with a significant increase in the likelihood of arrest.\n[Table 5. Effect of Marital Dissolution on the Probability of Arrest by Marriage Length, Within Individual: Divorce, Model 1 Coeff. = .113, SE = .228]\nReproduction data source(s):\nhttps://www.nlsinfo.org/investigator/pages/search#\nDescription of reproduction data:\nOriginal data obtained from the US Bureau of Labor Statistics. NLSY97 (National Longitudinal Study of Youth 1997) downloaded from the NLS investigator on March 1, 2022.\nReproduction criteria\n\n\n\n\n\n\n\n\n\n\nCriterion\nOriginal value\nPrecise reproduction\nApproximate reproduction\nNon-reproduction\n\n\n\n\nSample size\nn = 121\nn = 121\n103 \\(\\le\\) n \\(\\le\\) 139\nn &lt; 103 or n &gt; 139\n\n\np-value\np &gt; .05\np &gt; .05\n0 &lt; p \\(\\le\\) .05\np = 0\n\n\n\nNB: The sample size and focal coefficient are considered “approximately reproduced” when the reproduction result is within 15% of the original result. For p-values, the result is considered “approximately reproduced” when it is within 0.05 points of the original.\nAnalyst success criteria: The claim will be considered reproducible if a generalized mixed model predicting the log odds of arrest meets the approximate reproduction criteria for the sample size and the precise reproduction criteria for the p-value (p &gt; .05).\nReproduction results\n\n#Model 1\nmodel1 &lt;- run_model(months = 1:11) \nsummary(model1)$tTable[\"divorced\", \"p-value\"] #check p-value model 1\n\n[1] 0.9048844\n\nmodel1$dims$ngrps[1] #check sample size model 1\n\n id \n113 \n\n\nReproduction outcome: Based on the reproduction criteria, the claim did reproduce.\n\n\nCoded claim text (original paper): For short marriages, those lasting 23 months or less (models 1 and 2), neither getting divorced nor legally separating statistically alters one’s risk of arrest compared with when they were married. Conversely, for those in marriages lasting 24 months or longer, divorce is associated with a significant increase in the likelihood of arrest.\n[Table 5. Effect of Marital Dissolution on the Probability of Arrest by Marriage Length, Within Individual: Divorce, Model 2 Coeff. = -.442, SE = .396]\nReproduction data source(s):\nhttps://www.nlsinfo.org/investigator/pages/search#\nDescription of reproduction data:\nOriginal data obtained from the US Bureau of Labor Statistics. NLSY97 (National Longitudinal Study of Youth 1997) downloaded from the NLS investigator on March 1, 2022.\nReproduction criteria\n\n\n\n\n\n\n\n\n\n\nCriterion\nOriginal value\nPrecise reproduction\nApproximate reproduction\nNon-reproduction\n\n\n\n\nSample size\nn = 120\nn = 120\n102 \\(\\le\\) n \\(\\le\\) 138\nn &lt; 102 or n &gt; 138\n\n\np-value\np &gt; .05\np &gt; .05\n0 &lt; p \\(\\le\\) .05\np = 0\n\n\n\nNB: The sample size and focal coefficient are considered “approximately reproduced” when the reproduction result is within 15% of the original result. For p-values, the result is considered “approximately reproduced” when it is within 0.05 points of the original.\nAnalyst success criteria: The claim will be considered reproducible if a generalized mixed model predicting the log odds of arrest meets the approximate reproduction criteria for the sample size and the precise reproduction criteria for the p-value (p &gt; .05).\nReproduction results\n\n#Model 2\nmodel2 &lt;- run_model(months = 12:23) \nsummary(model2)$tTable[\"divorced\", \"p-value\"] #check p-value model 2\n\n[1] 0.8316677\n\nmodel2$dims$ngrps[1] #check sample size model 2\n\n id \n122 \n\n\nReproduction outcome: Based on the reproduction criteria, the claim did reproduce.\n\n\nCoded claim text (original paper): For short marriages, those lasting 23 months or less (models 1 and 2), neither getting divorced nor legally separating statistically alters one’s risk of arrest compared with when they were married. Conversely, for those in marriages lasting 24 months or longer, divorce is associated with a significant increase in the likelihood of arrest.\n[Table 5. Effect of Marital Dissolution on the Probability of Arrest by Marriage Length, Within Individual: Divorce, Model 3 Coeff. = .465, SE = .151, Sig. = p &lt; .01]\nReproduction data source(s):\nhttps://www.nlsinfo.org/investigator/pages/search#\nDescription of reproduction data:\nOriginal data obtained from the US Bureau of Labor Statistics. NLSY97 (National Longitudinal Study of Youth 1997) downloaded from the NLS investigator on March 1, 2022.\nReproduction criteria\n\n\n\n\n\n\n\n\n\n\nCriterion\nOriginal value\nPrecise reproduction\nApproximate reproduction\nNon-reproduction\n\n\n\n\nSample size\nn = 142\nn = 142\n121 \\(\\le\\) n \\(\\le\\) 163\nn &lt; 121 or n &gt; 163\n\n\nCoefficient\n\\(\\beta\\) = .465\n\\(\\beta\\) = .465\n.395 \\(\\le \\beta \\le\\) .535\n\\(\\beta\\) &lt; .395 or \\(\\beta\\) &gt; .535\n\n\n\nNB: The sample size and focal coefficient are considered “approximately reproduced” when the reproduction result is within 15% of the original result. For p-values, the result is considered “approximately reproduced” when it is within 0.05 points of the original.\nAnalyst success criteria: The claim will be considered reproducible if a generalized mixed model predicting the log odds of arrest meets the approximate reproduction criteria for the sample size and the approximate reproduction criteria for the coefficient of divorce.\nReproduction results\n\n#Model 3\nmodel3 &lt;- run_model(months = 24:35) \nsummary(model3)$tTable[\"divorced\", \"Value\"] #check estimate model 3\n\n[1] 0.4159142\n\nmodel3$dims$ngrps[1] #check sample size model 3\n\n id \n138 \n\n\nReproduction outcome: Based on the reproduction criteria, the claim did reproduce.\n\n\nCoded claim text (original paper): For short marriages, those lasting 23 months or less (models 1 and 2), neither getting divorced nor legally separating statistically alters one’s risk of arrest compared with when they were married. Conversely, for those in marriages lasting 24 months or longer, divorce is associated with a significant increase in the likelihood of arrest.\n[Table 5. Effect of Marital Dissolution on the Probability of Arrest by Marriage Length, Within Individual: Divorce, Model 4 Coeff. = .522, SE = .107, Sig. = p &lt; .001]\nReproduction data source(s):\nhttps://www.nlsinfo.org/investigator/pages/search#\nDescription of reproduction data:\nOriginal data obtained from the US Bureau of Labor Statistics. NLSY97 (National Longitudinal Study of Youth 1997) downloaded from the NLS investigator on March 1, 2022.\nReproduction criteria\n\n\n\n\n\n\n\n\n\n\nCriterion\nOriginal value\nPrecise reproduction\nApproximate reproduction\nNon-reproduction\n\n\n\n\nSample size\nn = 430\nn = 430\n366 \\(\\le\\) n \\(\\le\\) 495\nn &lt; 366 or n &gt; 495\n\n\nCoefficient\n\\(\\beta\\) = .522\n\\(\\beta\\) = .522\n.444 \\(\\le \\beta \\le\\) .600\n\\(\\beta\\) &lt; .444 or \\(\\beta\\) &gt; .600\n\n\np-value\np &lt; .001\np &lt; .001\n.001 \\(\\le\\) p \\(\\le\\) .051\np &gt; .051\n\n\n\nNB: The sample size and focal coefficient are considered “approximately reproduced” when the reproduction result is within 15% of the original result. For p-values, the result is considered “approximately reproduced” when it is within 0.05 points of the original.\nAnalyst success criteria: The claim will be considered reproducible if a generalized mixed model predicting the log odds of arrest meets the approximate reproduction criteria for the sample size, the coefficient of divorce, and the p-value.\nReproduction results\n\n#Model 4\nmodel4 &lt;- run_model(months = 36:longest_marriage) \nsummary(model4)$tTable[\"divorced\", c(\"Value\", \"p-value\")] #check estimate + p-value model 4\n\n     Value    p-value \n0.48170489 0.00562246 \n\nmodel4$dims$ngrps[1] #check sample size model 4\n\n id \n453 \n\n\nReproduction outcome: Based on the reproduction criteria, the claim did reproduce."
  },
  {
    "objectID": "score-criminology.html#description-of-materials-provided",
    "href": "score-criminology.html#description-of-materials-provided",
    "title": "3  SCORE Criminology",
    "section": "3.6 Description of materials provided",
    "text": "3.6 Description of materials provided\nAll materials on the OSF project may be shared publicly. Overview and description of the materials:\n\nBERSANI_Criminology_2013_zmYY_bushel_claims.md\nAn overview of all claims extracted from the paper\nBERSANI_Criminology_2013_zmYY_2w9mo_SDR_PREREGISTRATION.xlsx\nExcel workbook with the preregistered reproduction criteria for all claims part of the reproduction attempt\nNLSY97.dat\nData file (National Longitudinal Study of Youth 1997) downloaded from the NLS investigator\ncodebook.txt\nCodebook (data dictionary) accompanying NLSY97.dat\nhelper-functions.R\nHelper functions accompanying NLSY97.dat\nAnalysis-script.Rmd\nPreregistered analysis script (on randomly shuffled, blinded data)\nAnalysis-script.html\nKnitted output of the preregistered analysis script (on randomly shuffled, blinded data)\nTransparency Trail.Rmd\nTransparency trail of the reproduction attempt. This includes the analysis pipeline and full results/output of the analysis script (applied to the unblinded data)\nTransparency-Trail.pdf\nKnitted output of the transparency trail of the reproduction attempt. This includes the analysis pipeline and full results/output of the analysis script (applied to the unblinded data)"
  },
  {
    "objectID": "score-criminology.html#references",
    "href": "score-criminology.html#references",
    "title": "3  SCORE Criminology",
    "section": "3.7 References",
    "text": "3.7 References\nBersani, B. E.; Doherty, E. (2013). When the ties that bind unwind: Examining the enduring and situational processes of change behind the marriage effect. Criminology, 51(2), 399. https://doi.org/10.1111/1745-9125.12008\nBureau of Labor Statistics, U.S. Department of Labor. National Longitudinal Survey of Youth 1997 cohort, 1997-2009. Produced and distributed by the Center for Human Resource Research (CHRR), The Ohio State University. Columbus, OH: 2019."
  },
  {
    "objectID": "score-education.html",
    "href": "score-education.html",
    "title": "4  SCORE Education",
    "section": "",
    "text": "Reproduction analyst(s): Shilaan Alzahawi\nSCORE RR ID: 67539\nOSF Project: https://osf.io/pukd8/?view_only=f52f8b0d993a41ab99b345590e041e7c\nI did not deviate from the provided materials. All claims were successfully reproduced at the first attempt. (Note, however, that because not all covariates are available in the reproduction dataset, my analyst success criteria were relatively broad: for each claim, I evaluate whether (1) the p-value approximately reproduces and (2) the coefficient estimate is of the same sign). To design the analysis, I consulted the following materials:"
  },
  {
    "objectID": "score-education.html#reconstruction-of-data",
    "href": "score-education.html#reconstruction-of-data",
    "title": "4  SCORE Education",
    "section": "4.1 Reconstruction of data",
    "text": "4.1 Reconstruction of data\nData were drawn from the Cooperative Institutional Research Program (CIRP) at the UCLA Higher Education Research Institute (HERI), using the Senior Survey (1998). A subsample was created that excluded 2-year colleges and universities, historically Black colleges and universities, and students and institutions with preestablished thresholds of missing cases or items; the authors excluded students who had missing data or marked other on race, and institutions with fewer than 15 respondents.\nData was obtained from the HERI Data Archives (https://heri.ucla.edu/heri-data-archive/) for academics. This data is part of the public archives for scholarly access. It should not be posted publicly; instead, interested researchers should navigate to https://heri.ucla.edu/data-archive/ to register for the data archive and download the data there.\nVariables obtained from the 1998 Senior survey:\n\nGender (1 = female)\nRace (five dummy variables: African American, Native American, Asian American, Latino, and White)\nControl, 0 = public institution, 1 = private institution\nPart-time job on campus (1 = marked)\nLevel of involvement (1 = marked, standardized). Index of student responses on three items about whether or not they joined a fraternity or sorority; student government; or racial-ethnic organization\nCurricular diversity (1 = marked, standardized). Index of student responses on three items about whether or not they have participated in the following activities since entering college:\n\nTaken an ethnic studies course\nAttended a racial-cultural awareness workshop\nParticipated in an ethnic-racial student organization\n\nNB: “Participated in an ethnic/racial student organization” is an item for both level of involvement and curricular diversity\n\n\nCross-racial interaction (standardized). Coded on a 3-point scale from 1 = not at all to 3 = frequently. Responses to “At the college you entered as a freshman, indicate how often you…”\n\nInteracted with someone of a different racial-ethnic group in class\nStudied with someone from a different racial-ethnic group\nDined with someone from a different racial-ethnic group\nDated someone from a different racial-ethnic group\nSocialized with someone from a different racial-ethnic group\n\nNB: I cannot find the first item (interacted in class) in the data archives\n\n\nSelf-efficacy (standardized). Coded on a 5-point scale from 1 = lowest 10% to 5 = highest 10%. Includes following traits:\n\nDrive to achieve\nSelf-confidence (intellectual)\nCompetitiveness\nAcademic ability\nWriting ability\n\nNB: Appendix A seems to suggest that this outcome measure is standardized by age (“comparing with the average person the student’s age”), but I’m not entirely sure\n\n\nGeneral academic skills (standardized). Coded on a 5-point scale from 1 = lowest 10% to 5 = highest 10%. Includes following traits:\n\nAcademic ability\nWriting ability\n\nAppendix A seems to suggest that this pretest measure is standardized by age (“comparing with the average person the student’s age”), but I’m not entirely sure\nTable 1 footnote b indicates that this was actually coded from 1 = much weaker to 5 = much stronger (not 1 = lowest 10% to 5 = highest 10%)\nThese two items are also a part of the self-efficacy measure above\n\n\nRacial-cultural engagement (standardized). Coded on a 4-point scale from 1 = not important to 4 = essential. Student responses to two items about the importance of promoting racial understanding and helping others who are in difficulty.\nSize: Number of full-time undergraduate students enrolled at the institution\n\nNB: Cannot find this in the data archives. Likely obtained from outside data source.\n\n%of underrepresented minority students: %Latino + %Black + %Native American\n\nNB: Likely obtained from outside data source, but can calculate within the survey respondents.\n\n\n\ndf &lt;- read_sav(\n  file = here(\"data/CIRP_Survey.zSAV\"), \n  col_select = c(\n    #Demographics\n    \"YEAR\",#Year\n    \"ACERECODE\", #College ID\n    \"SUBJID\",  #Subject ID\n    \"HBCU\", #Historically Black College or University\n    \"INSTTYPE\", #Institutional type\n    \"INSTCONT\", #Institution Control (1 = public, 2 = private)\n    \"SEX\", #Biological Sex (1 = male, 2 = female)\n    #Race: 1 = Native, 2 = Asian, 3 = Black, 4 = Hispanic, 5 = White,\n    \"RACEGROUP\", #Race/Ethnicity Group 6/7 = Other\n    \n    #Curricular diversity: 3 items\n    \"COLACT29_9406\", #Enrolled in an ethnic studies course [marked]\n    \"COLACT02_9406\", #Attended racial/cultural awareness workshop [marked]\n    \"COLACT17_9406\", #Participated in an ethnic/racial student organization\n    \n    #Level of involvement: 3 items\n    \"COLACT14_9406\", #Joined a social fraternity or sorority\n    \"COLACT23_9406\", #Participated in student government\n    #\"COLACT17_9406\" #Participated in an ethnic/racial student organization\n    \n    #Cross-racial interaction: 5 items\n    #NOTE: I cannot find item 1 (interacted in class) in the Survey\n    \"ETHACT7\", #Studied with someone from a different racial/ethnic group\n    \"ETHACT2\", #Dined with someone from a different racial/ethnic group\n    \"ETHACT1\", #Dated someone from a different racial/ethnic background\n    \"GENACT30\", #Socialized with someone from a different racial-ethnic group \n    \n    #Racial-cultural engagement: 2 items\n    \"GOAL12\", #Helping to promote racial understanding\n    \"GOAL11\", #Helping others who are in difficulty\n    \n    #Self-esteem: 3 items + General academic skills\n    \"RATE09\", #Drive to achieve\n    \"RATE22\", #Self-confidence (intellectual)\n    \"RATE04\", #Competitiveness\n    \n    #General academic skills: 2 items\n    \"RATE01\", #Self-rated academic ability\n    \"RATE28\", #Self-rated writing ability\n    \n    #Part-time job on campus\n    \"COLACT12_9406\"\n    )\n  )\n\n#Recode the variables of interest\ndf &lt;- df %&gt;% \n  filter(\n    YEAR == 1998 & #Only include responses for 1998\n    INSTTYPE != 3 & #Exclude 2yr colleges\n    HBCU != 2 #Exclude Historically Black Colleges or Universities\n  ) %&gt;% \n  mutate(\n    #public institution = 0, private institution = 1\n    private = ifelse(INSTCONT == 1, 0, ifelse(INSTCONT == 2, 1, NA)),\n    #gender: 1 = female\n    female = ifelse(SEX == 1, 0, ifelse(SEX == 2, 1, NA)),\n    #race\n    black = ifelse(RACEGROUP == 3, 1, 0),\n    native = ifelse(RACEGROUP == 1, 1, 0),\n    asian = ifelse(RACEGROUP == 2, 1, 0),\n    hispanic = ifelse(RACEGROUP == 4, 1, 0),\n    white = ifelse(RACEGROUP == 5, 1, 0),\n    other = ifelse(RACEGROUP %in% 6:7, 1, 0),\n    ethnic_studies = ifelse(COLACT29_9406 == 2, 1, 0),\n    cultural_workshop = ifelse(COLACT02_9406 == 2, 1, 0),\n    ethnic_organization = ifelse(COLACT17_9406 == 2, 1, 0),\n    curricular_diversity = rowMeans(cbind(\n      ethnic_studies, #Enrolled in an ethnic studies course [marked]\n      cultural_workshop, #Attended racial/cultural awareness workshop [marked]\n      ethnic_organization #Participated in an ethnic/racial student organization\n      ), na.rm = TRUE\n    ),\n    fraternity = ifelse(COLACT14_9406 == 2, 1, 0),\n    studentgov = ifelse(COLACT23_9406 == 2, 1, 0),\n    involvement = rowMeans(cbind(\n      fraternity,\n      studentgov,\n      ethnic_organization\n      ), na.rm = TRUE\n    ),\n    cross_racial_int = rowMeans(cbind(\n      ETHACT7, #Studied with someone from a different racial/ethnic group\n      ETHACT2, #Dined with someone from a different racial/ethnic group\n      ETHACT1, #Dated someone from a different racial/ethnic background\n      GENACT30 #Socialized with someone from a different racial-ethnic group\n      ), na.rm = TRUE\n    ),\n    self_efficacy = rowMeans(cbind(\n      RATE09, #Drive to achieve\n      RATE22, #Self-confidence (intellectual)\n      RATE04, #Competitiveness\n      RATE01, #Academic ability\n      RATE28  #Writing ability\n      ), na.rm = TRUE\n    ),\n    academic_skills = rowMeans(cbind(\n      RATE01, #Academic ability\n      RATE28  #Writing ability\n      ), na.rm = TRUE\n    ),\n    racial_engagement = rowMeans(cbind(\n      GOAL11, #Helping others who are in difficulty\n      GOAL12  #Helping to promote racial understanding\n      ), na.rm = TRUE\n    ),\n    part_time_job = ifelse(COLACT12_9406 == 2, 1, 0),\n  ) \n\n#Create CSV file for seniors in 1998\nwrite_csv(df, \"data/CIRP_Survey.csv\")"
  },
  {
    "objectID": "score-education.html#data-cleaning-and-processing",
    "href": "score-education.html#data-cleaning-and-processing",
    "title": "4  SCORE Education",
    "section": "4.2 Data cleaning and processing",
    "text": "4.2 Data cleaning and processing\nStandardize the following individual-level variables:\n\nSelf-efficacy\nAcademic skills\nRacial engagement\nInvolvement\nCurricular diversity\nCross-racial interaction\n\nCalculate the following institution-level variables:\n\nAverage curricular diversity (the average of individual scores by institution)\nAverage cross-racial interaction\nProportion of underrepresented minority (URM) students (i.e., the combined proportional representation of African Americans, Hispanic Americans, and Native Americans)\n\n\ndf &lt;- read_csv(here(\"data/CIRP_Survey.csv\")) %&gt;% \n  dplyr::select(\n    ACERECODE:SUBJID, \n    RACEGROUP,\n    private:part_time_job\n    ) %&gt;% \n  filter(\n    #exclude individuals who marked \"Other\" on race or did not answer\n    RACEGROUP %in% 1:5 & !is.na(RACEGROUP) \n  ) %&gt;% \n  group_by(ACERECODE) %&gt;% #group by college\n  mutate(institution_n = n()) %&gt;% #count the observations per institute\n  ungroup() %&gt;% \n  filter(institution_n &gt; 14) #exclude institutions with fewer than 14 obs\n\n#Clean up names\nnames(df) &lt;- tolower(names(df))\n\nstandardize &lt;- function(x) {as.vector(scale(x))}\n\ndf &lt;- df %&gt;%\n  mutate(\n    #Standardize all relevant level 1 predictors\n    self_efficacy = standardize(self_efficacy),\n    academic_skills = standardize(academic_skills),\n    racial_engagement = standardize(racial_engagement),\n    involvement = standardize(involvement),\n    curricular_diversity = standardize(curricular_diversity),\n    cross_racial_int = standardize(cross_racial_int),\n    urm = rowSums(cbind(black + native + hispanic), na.rm = TRUE)\n  ) %&gt;%\n  group_by(acerecode) %&gt;%\n  mutate(\n    #Get the level 2 predictors (institution level means)\n    curricular_diversity_mean = mean(curricular_diversity, na.rm = TRUE),\n    cross_racial_int_mean = mean(cross_racial_int, na.rm = TRUE),\n    part_time_job_mean = mean(part_time_job, na.rm = TRUE),\n    female_mean = mean(female, na.rm = TRUE),\n    black_mean = mean(black, na.rm = TRUE),\n    native_mean = mean(native, na.rm = TRUE),\n    hispanic_mean = mean(hispanic, na.rm = TRUE),\n    urm_mean = mean(urm, na.rm = TRUE),\n    involvement_mean = mean(involvement, na.rm = TRUE)\n  )"
  },
  {
    "objectID": "score-education.html#statistical-model",
    "href": "score-education.html#statistical-model",
    "title": "4  SCORE Education",
    "section": "4.3 Statistical model",
    "text": "4.3 Statistical model\nInformation obtained from paper:\n\nThree outcomes: self-efficacy, general academic skills, and racial-cultural engagement\nLevel 1 predictors\n\nCurricular diversity\nCross-racial interaction (CRI)\nPart-time job on campus\nPretest of outcome (drawn from the Freshman Survey 1994)\nHighschool GPA\nSES (see note below under “Discrepancies”)\nLive on campus\nNative American\nAsian\nAfrican American\nHispanic\nFemale (0 = male, 1 = female)\nLevel of involvement\n\nLevel 2 predictors\n\n% URM Students\nSize of college\nSelectivity of college\nControl: Private\nAverage curricular diversity\nAverage cross-racial interaction\nAverage part-time job on campus\nPretest of outcome\nAverage highschool GPA\nAverage SES (see note below under “Discrepancies”)\nAverage live on campus\nAverage female\nAverage level of involvement\nAverage race\n\n\n\n4.3.1 Discrepancies\nThere are two discrepancies between the original paper and my reproduction attempt.\nFirst, in the final model equations (p.332-333), “SES” is included as a predictor. However, SES is mentioned nowhere in the paper: not in the outcome tables, the descriptive statistics, or in the description of the methods and measures (so I do not know where/how to get or calculate this measure). I’m assuming this is a remnant of a previous version of the paper, and that SES is not actually included in the final model. Thus, I do not include SES in the reproduction attempt.\nSecond, the college and student identifiers seem to have been recoded over time (i.e., they are not constant across different yearly iterations of the Survey). As a result, I cannot merge the Survey with outside institution-level data (i.e., undergraduate enrollment and % of URM students), nor merge the 1998 Survey with previous iterations to obtain the covariates measured in earlier years (i.e., pretests of the three outcomes, high school GPA, and on-campus residency).\nIn sum, I do not have access to the following covariates mentioned in the paper:\n\nSize of college (undergraduate enrollment)\nSelectivity (Average SAT Verbal and SAT Math scores of entering freshmen)\n%of underrepresented minority (URM) students: %Hispanic + %Black + %Native American\n\nWhile I do not have access to the overall % of URM students for each institution, I can calculate this percentage for the survey respondents and still include this measure\n\nPretest of outcome\nHighschool GPA\nLive on campus (yes/no)\n\nTaking these discrepancies into account, I run the following statistical model:\n\\[\n\\begin{split}\nY_{ij} = ~&\\gamma_{00} + \\gamma_{01}(\\text{AVG: URM}) + \\gamma_{04} (\\text{Control: Private}) + \\gamma_{05} (\\text{AVG: Curricular diversity}) +  \\\\\n&\\gamma_{06}(\\text{AVG: CRI}) +\\gamma_{07}(\\text{AVG: Part-time job on campus}) + \\gamma_{012}(\\text{AVG: Female}) +  \\\\\n&\\gamma_{013}(\\text{AVG: Involvement}) +  \\gamma_{10}(\\text{Curricular diversity}) + \\gamma_{11}(\\text{Curricular diversity}*\\text{AVG: URM}) + \\\\\n&\\gamma_{12}(\\text{Curricular diversity}*\\text{AVG: Curricular diversity}) +  \\gamma_{13}(\\text{Curricular diversity}*\\text{AVG: CRI}) +  \\\\\n&\\gamma_{14}(\\text{Curricular diversity}*\\text{AVG: Part-time job on campus}) +  \\gamma_{20}(\\text{CRI}) + \\\\\n&\\gamma_{21}(\\text{CRI}*\\text{AVG: URM}) + \\gamma_{22}(\\text{CRI}*\\text{AVG: Curricular diversity}) +  \\gamma_{23}(\\text{CRI}*\\text{AVG: CRI}) + \\\\\n& \\beta_{3j}(\\text{Part-time job on campus}) + \\beta_{8j}(\\text{Native American}) + \\beta_{9j}(\\text{Asian}) +  \\beta_{10j}(\\text{African American}) + \\\\\n&\\beta_{11j}(\\text{Hispanic}) +  \\beta_{12j}(\\text{Female}) + \\beta_{13j}(\\text{Involvement})\n\\end{split}\n\\]\n\nrun_lmer &lt;- function(outcome) {\n  lmer(\n  outcome ~\n    #g01*AVG:URM + g04*Private + g05*AVG_curricular_div + g_06*AVG:CRI\n    urm_mean + private + curricular_diversity_mean + cross_racial_int_mean +\n    #g07*AVG:Part_time + g012*AVG:Female + g013*AVG:involvement + \n    part_time_job_mean + female_mean + involvement_mean + \n    #g10*curricular_div + g11*curricular_div*AVG:URM + \n    curricular_diversity + curricular_diversity*urm_mean + \n    #g12*curricular_div*AVG:curricular_div\n    curricular_diversity*curricular_diversity_mean + \n    #g13*curricular_div*AVG:CRI\n    curricular_diversity*cross_racial_int_mean +\n    #g14*curricular_div*AVG:Part time\n    curricular_diversity*part_time_job_mean +\n    #g20*CRI   +     g21*CRI*AVG:URM + \n    cross_racial_int + cross_racial_int*urm_mean + \n    #g22*CRI*AVG:curricular_div\n    cross_racial_int*curricular_diversity_mean + \n    #g23*CRI*AVG:CRI         +               b3j*part_time + b8j*native\n    cross_racial_int*cross_racial_int_mean + part_time_job + native +\n    #b9j*asian + b10j*black + b11j*hispanic + b12j*female + b13*involvement\n    asian + black + hispanic + female + involvement +\n    #random intercept for college\n    (1 | acerecode),\n  data = df,\n  verbose = FALSE\n  )\n}\n\n#Run models for the three outcomes\nfit_efficacy &lt;- run_lmer(df$self_efficacy) %&gt;% tidy()\nfit_academic &lt;- run_lmer(df$academic_skills) %&gt;% tidy()\nfit_engagement &lt;- run_lmer(df$racial_engagement) %&gt;% tidy()\n\n\n\n4.3.2 Analyst success criteria\nAbove, I described two important discrepancies between the original paper and my reproduction attempt: (1) I do not have access to college size; college selectivity; pretests of the outcomes; highschool GPA; and whether students live on campus and (2) I rely on a self-calculated percentage of URM students, based on the survey respondents.\nThese covariates likely impact the coefficient estimates, but we can still evaluate if the main predictors (curricular diversity and cross-racial interactions) are significant, with an effect in the same direction. Thus, the analyst success criteria below are relatively broad: for each claim, I evaluate whether (1) the p-value approximately reproduces and (2) the coefficient estimate is of the same sign."
  },
  {
    "objectID": "score-education.html#claim-evaluations",
    "href": "score-education.html#claim-evaluations",
    "title": "4  SCORE Education",
    "section": "4.4 Claim evaluations",
    "text": "4.4 Claim evaluations\nBushel claims obtained from the OSF here.\n\nClaim 1Claim 2Claim 3Claim 4Claim 5Claim 6Claim 7\n\n\nCoded claim text (original paper): Table 3 reports the results of the final HLM model for each of the three outcome measures. As shown in the first two columns of numbers in Table 3, the coefficients for the curricular diversity slope base (\\(\\gamma_{10}\\) = .08, t = 4.01) are statistically significant, suggesting a significant positive effect on this self-efficacy measure. In other words, students who were more involved in workshops or classes that incorporated issues concerning diversity tended to also report higher levels of self-efficacy.\n[Table 3, Self-Efficacy, Curricular diversity slope Base (\\(\\gamma_{10}\\)): Coefficient (SE) = 0.08 (0.02), t Ratio = 4.01, p &lt; .001]\nReproduction data source(s): https://heri.ucla.edu/data-archive/\nDescription of reproduction data: Original Data obtained from the Higher Education Research Institute (HERI). Cooperative Institutional Research Program (CIRP) College Senior Survey Trends downloaded from the CIRP data Data Archives on March 4, 2022.\nPrimary reproduction criteria\n\n\n\n\n\n\n\n\n\n\nCriterion\nOriginal value\nPrecise reproduction\nApproximate reproduction\nNon-reproduction\n\n\n\n\nCoefficient\n\\(\\gamma_{10}\\) = 0.08\n\\(\\gamma_{10}\\) = 0.08\n0.07 \\(\\le \\gamma_{10} \\le\\) 0.09\n\\(\\gamma_{10}\\) &lt; 0.07 or \\(\\gamma_{10}\\) &gt; 0.09\n\n\nTest statistic\nt = 4.01\nt = 4.01\n3.41 \\(\\le\\) t \\(\\le\\) 4.61\nt &lt; 3.41 or t &gt; 4.61\n\n\np-value\np &lt; .001\np &lt; .001\n.001 \\(\\le\\) p \\(\\le\\) .051\np &gt; .051\n\n\n\nNB: The sample size and focal coefficient are considered “approximately reproduced” when the reproduction result is within 15% of the original result. For p-values, the result is considered “approximately reproduced” when it is within 0.05 points of the original.\nAnalyst success criteria: Because not all covariates are available in the reproduction dataset (which will likely impact the coefficient estimates), the claim will be considered reproducible if it meets the approximate reproduction criteria for the p-value and the focal coefficient is of the same sign (i.e., a positive coefficient estimate).\nReproduction results\n\nfit_efficacy %&gt;% \n  filter(term == \"curricular_diversity\") %&gt;% \n  select(term, estimate, statistic, p.value)\n\n# A tibble: 1 × 4\n  term                 estimate statistic   p.value\n  &lt;chr&gt;                   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 curricular_diversity    0.114      4.35 0.0000139\n\n\nReproduction outcome: Based on the reproduction criteria, the claim did reproduce.\n\n\nCoded claim text (original paper): Table 3 reports the results of the final HLM model for each of the three outcome measures. As shown in the first two columns of numbers in Table 3, the coefficients for the CRI slope base (\\(\\gamma_{20}\\) = .14, t = 7.39) are statistically significant, suggesting a significant positive effect on this self-efficacy measure. In other words, students who interacted more with others of another race, tended to also report higher levels of self-efficacy.\n[Table 3, Self-Efficacy, CRI slope Base (\\(\\gamma_{20}\\)): Coefficient (SE) = 0.14 (0.02), t Ratio = 7.39, p &lt; .001]\nReproduction data source(s): https://heri.ucla.edu/data-archive/\nDescription of reproduction data: Original Data obtained from the Higher Education Research Institute (HERI). Cooperative Institutional Research Program (CIRP) College Senior Survey Trends downloaded from the CIRP data Data Archives on March 4, 2022.\nPrimary reproduction criteria\n\n\n\n\n\n\n\n\n\n\nCriterion\nOriginal value\nPrecise reproduction\nApproximate reproduction\nNon-reproduction\n\n\n\n\nCoefficient\n\\(\\gamma_{20}\\) = 0.14\n\\(\\gamma_{20}\\) = 0.14\n0.12 \\(\\le \\gamma_{20} \\le\\) 0.16\n\\(\\gamma_{20}\\) &lt; 0.12 or \\(\\gamma_{20}\\) &gt; 0.16\n\n\nTest statistic\nt = 7.39\nt = 7.39\n6.28 \\(\\le\\) t \\(\\le\\) 8.50\nt &lt; 6.28 or t &gt; 8.50\n\n\np-value\np &lt; .001\np &lt; .001\n.001 \\(\\le\\) p \\(\\le\\) .051\np &gt; .051\n\n\n\nNB: The sample size and focal coefficient are considered “approximately reproduced” when the reproduction result is within 15% of the original result. For p-values, the result is considered “approximately reproduced” when it is within 0.05 points of the original.\nAnalyst success criteria: Because not all covariates are available in the reproduction dataset (which will likely impact the coefficient estimates), the claim will be considered reproducible if it meets the approximate reproduction criteria for the p-value and the focal coefficient is of the same sign (i.e., a positive coefficient estimate).\nReproduction results\n\nfit_efficacy %&gt;% \n  filter(term == \"cross_racial_int\") %&gt;% \n  select(term, estimate, statistic, p.value)\n\n# A tibble: 1 × 4\n  term             estimate statistic  p.value\n  &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 cross_racial_int   0.0476      6.20 5.86e-10\n\n\nReproduction outcome: Based on the reproduction criteria, the claim did reproduce.\n\n\nCoded claim text (original paper): The second set of results in Table 3 shows the findings for the general academic skills measure. Again, focusing on the key variables of interest, the student-level characteristics of curricular diversity (\\(\\gamma_{10}\\) = .17, t = 10.40) exerted significant positive effects on the general academic skills measure. That is, students who participated in more workshops or diversity-related classes tended to also report higher levels of general academic skills.\n[Table 3, General Academic Skills, Curricular diversity slope Base (\\(\\gamma_{10}\\)): Coefficient (SE) = 0.17 (0.02), t Ratio = 10.40, p &lt; .001]\nReproduction data source(s): https://heri.ucla.edu/data-archive/\nDescription of reproduction data: Original Data obtained from the Higher Education Research Institute (HERI). Cooperative Institutional Research Program (CIRP) College Senior Survey Trends downloaded from the CIRP data Data Archives on March 4, 2022.\nPrimary reproduction criteria\n\n\n\n\n\n\n\n\n\n\nCriterion\nOriginal value\nPrecise reproduction\nApproximate reproduction\nNon-reproduction\n\n\n\n\nCoefficient\n\\(\\gamma_{10}\\) = 0.17\n\\(\\gamma_{10}\\) = 0.17\n0.14 \\(\\le \\gamma_{10} \\le\\) 0.20\n\\(\\gamma_{10}\\) &lt; 0.14 or \\(\\gamma_{10}\\) &gt; 0.20\n\n\nTest statistic\nt = 10.40\nt = 10.40\n8.84 \\(\\le\\) t \\(\\le\\) 11.96\nt &lt; 8.84 or t &gt; 11.96\n\n\np-value\np &lt; .001\np &lt; .001\n.001 \\(\\le\\) p \\(\\le\\) .051\np &gt; .051\n\n\n\nNB: The sample size and focal coefficient are considered “approximately reproduced” when the reproduction result is within 15% of the original result. For p-values, the result is considered “approximately reproduced” when it is within 0.05 points of the original.\nAnalyst success criteria: Because not all covariates are available in the reproduction dataset (which will likely impact the coefficient estimates), the claim will be considered reproducible if it meets the approximate reproduction criteria for the p-value and the focal coefficient is of the same sign (i.e., a positive coefficient estimate).\nReproduction results\n\nfit_academic %&gt;% \n  filter(term == \"curricular_diversity\") %&gt;% \n  select(term, estimate, statistic, p.value)\n\n# A tibble: 1 × 4\n  term                 estimate statistic     p.value\n  &lt;chr&gt;                   &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n1 curricular_diversity    0.138      5.23 0.000000172\n\n\nReproduction outcome: Based on the reproduction criteria, the claim did reproduce.\n\n\nCoded claim text (original paper): The second set of results in Table 3 shows the findings for the general academic skills measure. Again, focusing on the key variables of interest, the student-level characteristics of CRI (\\(\\gamma_{20}\\) = .16, t = 9.74) exerted significant positive effects on the general academic skills measure. That is, students who interacted more often with students of another race tended to also report higher levels of general academic skills.\n[Table 3, General Academic Skills, CRI slope Base (\\(\\gamma_{20}\\)): Coefficient (SE) = 0.16 (0.02), t Ratio = 9.74, p &lt; .001]\nReproduction data source(s): https://heri.ucla.edu/data-archive/\nDescription of reproduction data: Original Data obtained from the Higher Education Research Institute (HERI). Cooperative Institutional Research Program (CIRP) College Senior Survey Trends downloaded from the CIRP data Data Archives on March 4, 2022.\nPrimary reproduction criteria\n\n\n\n\n\n\n\n\n\n\nCriterion\nOriginal value\nPrecise reproduction\nApproximate reproduction\nNon-reproduction\n\n\n\n\nCoefficient\n\\(\\gamma_{20}\\) = 0.16\n\\(\\gamma_{20}\\) = 0.16\n0.14 \\(\\le \\gamma_{20} \\le\\) 0.18\n\\(\\gamma_{20}\\) &lt; 0.14 or \\(\\gamma_{20}\\) &gt; 0.18\n\n\nTest statistic\nt = 9.74\nt = 9.74\n8.28 \\(\\le\\) t \\(\\le\\) 11.20\nt &lt; 8.28 or t &gt; 11.20\n\n\np-value\np &lt; .001\np &lt; .001\n.001 \\(\\le\\) p \\(\\le\\) .051\np &gt; .051\n\n\n\nNB: The sample size and focal coefficient are considered “approximately reproduced” when the reproduction result is within 15% of the original result. For p-values, the result is considered “approximately reproduced” when it is within 0.05 points of the original.\nAnalyst success criteria: Because not all covariates are available in the reproduction dataset (which will likely impact the coefficient estimates), the claim will be considered reproducible if it meets the approximate reproduction criteria for the p-value and the focal coefficient is of the same sign (i.e., a positive coefficient estimate).\nReproduction results\n\nfit_academic %&gt;% \n  filter(term == \"cross_racial_int\") %&gt;% \n  select(term, estimate, statistic, p.value)\n\n# A tibble: 1 × 4\n  term             estimate statistic p.value\n  &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 cross_racial_int   0.0216      2.80 0.00518\n\n\nReproduction outcome: Based on the reproduction criteria, the claim did reproduce.\n\n\nCoded claim text (original paper): Additionally, the student body’s average level of curricular diversity engagement (\\(\\gamma_{05}\\) = .31, t = 3.84) also had a significant positive effect on this measure. So students who attended institutions where more students participated in workshops or classes that considered diversity issues tended to also report higher levels of general academic skills, regardless of their own personal involvement.\n[Table 3, General Academic Skills, AVG: Curricular diversity (\\(\\gamma_{05}\\)): Coefficient (SE) = 0.31 (0.08), t Ratio = 3.84, p &lt; .001]\nReproduction data source(s): https://heri.ucla.edu/data-archive/\nDescription of reproduction data: Original Data obtained from the Higher Education Research Institute (HERI). Cooperative Institutional Research Program (CIRP) College Senior Survey Trends downloaded from the CIRP data Data Archives on March 4, 2022.\nPrimary reproduction criteria\n\n\n\n\n\n\n\n\n\n\nCriterion\nOriginal value\nPrecise reproduction\nApproximate reproduction\nNon-reproduction\n\n\n\n\nCoefficient\n\\(\\gamma_{05}\\) = 0.31\n\\(\\gamma_{05}\\) = 0.31\n0.26 \\(\\le \\gamma_{05} \\le\\) 0.36\n\\(\\gamma_{05}\\) &lt; 0.26 or \\(\\gamma_{05}\\) &gt; 0.36\n\n\nTest statistic\nt = 3.84\nt = 3.84\n3.26 \\(\\le\\) t \\(\\le\\) 4.42\nt &lt; 3.26 or t &gt; 4.42\n\n\np-value\np &lt; .001\np &lt; .001\n.001 \\(\\le\\) p \\(\\le\\) .051\np &gt; .051\n\n\n\nNB: The sample size and focal coefficient are considered “approximately reproduced” when the reproduction result is within 15% of the original result. For p-values, the result is considered “approximately reproduced” when it is within 0.05 points of the original.\nAnalyst success criteria: Because not all covariates are available in the reproduction dataset (which will likely impact the coefficient estimates), the claim will be considered reproducible if it meets the approximate reproduction criteria for the p-value and the focal coefficient is of the same sign (i.e., a positive coefficient estimate).\nReproduction results\n\nfit_academic %&gt;% \n  filter(term == \"curricular_diversity_mean\") %&gt;% \n  select(term, estimate, statistic, p.value)\n\n# A tibble: 1 × 4\n  term                      estimate statistic p.value\n  &lt;chr&gt;                        &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 curricular_diversity_mean    0.129      2.30  0.0224\n\n\nReproduction outcome: Based on the reproduction criteria, the claim did reproduce.\n\n\nCoded claim text (original paper): The last set of results reported in the two columns of numbers on the far right in Table 3 shows that curricular diversity (\\(\\gamma_{10}\\) = .22, t = 18.57) had significant positive effects on the racial-cultural engagement measure.\n[Table 3, Racial/Cultural Engagement, Curricular diversity slope Base (\\(\\gamma_{10}\\)): Coefficient (SE) = 0.22 (0.01), t Ratio = 18.57, p &lt; .001]\nReproduction data source(s): https://heri.ucla.edu/data-archive/\nDescription of reproduction data: Original Data obtained from the Higher Education Research Institute (HERI). Cooperative Institutional Research Program (CIRP) College Senior Survey Trends downloaded from the CIRP data Data Archives on March 4, 2022.\nPrimary reproduction criteria\n\n\n\n\n\n\n\n\n\n\nCriterion\nOriginal value\nPrecise reproduction\nApproximate reproduction\nNon-reproduction\n\n\n\n\nCoefficient\n\\(\\gamma_{10}\\) = 0.22\n\\(\\gamma_{10}\\) = 0.22\n0.19 \\(\\le \\gamma_{10} \\le\\) 0.25\n\\(\\gamma_{10}\\) &lt; 0.19 or \\(\\gamma_{10}\\) &gt; 0.25\n\n\nTest statistic\nt = 18.57\nt = 18.57\n15.78 \\(\\le\\) t \\(\\le\\) 21.36\nt &lt; 15.78 or t &gt; 21.36\n\n\np-value\np &lt; .001\np &lt; .001\n.001 \\(\\le\\) p \\(\\le\\) .051\np &gt; .051\n\n\n\nNB: The sample size and focal coefficient are considered “approximately reproduced” when the reproduction result is within 15% of the original result. For p-values, the result is considered “approximately reproduced” when it is within 0.05 points of the original.\nAnalyst success criteria: Because not all covariates are available in the reproduction dataset (which will likely impact the coefficient estimates), the claim will be considered reproducible if it meets the approximate reproduction criteria for the p-value and the focal coefficient is of the same sign (i.e., a positive coefficient estimate).\nReproduction results\n\nfit_engagement %&gt;% \n  filter(term == \"curricular_diversity\") %&gt;% \n  select(term, estimate, statistic, p.value)\n\n# A tibble: 1 × 4\n  term                 estimate statistic  p.value\n  &lt;chr&gt;                   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 curricular_diversity    0.165      6.60 4.23e-11\n\n\nReproduction outcome: Based on the reproduction criteria, the claim did reproduce.\n\n\nCoded claim text (original paper): The last set of results reported in the two columns of numbers on the far right in Table 3 shows that CRI (\\(\\gamma_{20}\\) = .35, t = 32.28) had significant positive effects on the racial-cultural engagement measure.\n[Table 3, Racial/Cultural Engagement, CRI slope Base (\\(\\gamma_{20}\\)): Coefficient (SE) = 0.35 (0.01), t Ratio = 32.28, p &lt; .001]\nReproduction data source(s): https://heri.ucla.edu/data-archive/\nDescription of reproduction data: Original Data obtained from the Higher Education Research Institute (HERI). Cooperative Institutional Research Program (CIRP) College Senior Survey Trends downloaded from the CIRP data Data Archives on March 4, 2022.\nPrimary reproduction criteria\n\n\n\n\n\n\n\n\n\n\nCriterion\nOriginal value\nPrecise reproduction\nApproximate reproduction\nNon-reproduction\n\n\n\n\nCoefficient\n\\(\\gamma_{20}\\) = 0.35\n\\(\\gamma_{20}\\) = 0.35\n0.30 \\(\\le \\gamma_{20} \\le\\) 0.40\n\\(\\gamma_{20}\\) &lt; 0.30 or \\(\\gamma_{20}\\) &gt; 0.40\n\n\nTest statistic\nt = 32.28\nt = 32.28\n27.44 \\(\\le\\) t \\(\\le\\) 37.12\nt &lt; 27.44 or t &gt; 37.12\n\n\np-value\np &lt; .001\np &lt; .001\n.001 \\(\\le\\) p \\(\\le\\) .051\np &gt; .051\n\n\n\nNB: The sample size and focal coefficient are considered “approximately reproduced” when the reproduction result is within 15% of the original result. For p-values, the result is considered “approximately reproduced” when it is within 0.05 points of the original.\nAnalyst success criteria: Because not all covariates are available in the reproduction dataset (which will likely impact the coefficient estimates), the claim will be considered reproducible if it meets the approximate reproduction criteria for the p-value and the focal coefficient is of the same sign (i.e., a positive coefficient estimate).\nReproduction results\n\nfit_engagement %&gt;% \n  filter(term == \"cross_racial_int\") %&gt;% \n  select(term, estimate, statistic, p.value)\n\n# A tibble: 1 × 4\n  term             estimate statistic   p.value\n  &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 cross_racial_int    0.226      30.9 5.35e-207\n\n\nReproduction outcome: Based on the reproduction criteria, the claim did reproduce."
  },
  {
    "objectID": "score-education.html#description-of-materials-provided",
    "href": "score-education.html#description-of-materials-provided",
    "title": "4  SCORE Education",
    "section": "4.5 Description of materials provided",
    "text": "4.5 Description of materials provided\nAll materials on the OSF project, except for the reproduction data, may be shared publicly. Overview and description of the materials:\n\nDenson_AmEduResJourn_2009_zb3Y_bushel_claims.md\nAn overview of all claims extracted from the paper\nDenson_AmEduResJourn_2009_zb3Y_67539_SDR_PREREGISTRATION.xlsx\nExcel workbook with the preregistered reproduction criteria for all claims part of the reproduction attempt\nCodebook.pdf\nCodebook (data dictionary) accompanying CIRP_Survey.zSAV\nCIRP_Survey.zSAV\nReproduction data, obtained from the Higher Education Research Institute. Data was obtained from the HERI Data Archives (https://heri.ucla.edu/heri-data-archive/) for academics. This data is part of the public archives for scholarly access. It should not be posted publicly; instead, interested researchers should navigate to https://heri.ucla.edu/data-archive/ to register for the data archive and download the data there.\nCIRP_Survey.csv\nProcessed and cleaned data, on which all analyses were run\nAnalysis-script-preregistration.Rmd\nPreregistered analysis script (on randomly shuffled, blinded data)\nAnalysis-script-preregistration.html\nKnitted output of the preregistered analysis script (on randomly shuffled, blinded data)\nTransparency Trail.Rmd\nTransparency trail of the reproduction attempt. This includes the analysis pipeline and full results/output of the analysis script (applied to the unblinded data)\nTransparency-Trail.html\nKnitted output of the transparency trail of the reproduction attempt. This includes the analysis pipeline and full results/output of the analysis script (applied to the unblinded data)"
  },
  {
    "objectID": "score-education.html#references",
    "href": "score-education.html#references",
    "title": "4  SCORE Education",
    "section": "4.6 References",
    "text": "4.6 References\nDenson & Chang. (2009). Racial Diversity Matters: The Impact of Diversity-Related Student Engagement and Institutional Context. American Educational Research Journal, 46(2), 322-353. https://doi.org/10.3102/0002831208323278\nUCLA Higher Education Research Institute (HERI). Cooperative Institutional Research Program (CIRP) College Senior Survey Trends. Retrieved from https://heri.ucla.edu/data-archive/."
  },
  {
    "objectID": "management.html",
    "href": "management.html",
    "title": "5  Management Science",
    "section": "",
    "text": "Reproducible analysis script for the results reported in the following working paper:\nAlzahawi, S., Reit, E.S., & Flynn, F.J. A Legend in One’s Own Mind: The Link Between Ambition and Leader Effectiveness."
  },
  {
    "objectID": "management.html#load-packages",
    "href": "management.html#load-packages",
    "title": "5  Management Science",
    "section": "5.1 Load packages",
    "text": "5.1 Load packages\n\nlibrary(tidyverse) #for data wrangling\nlibrary(papaja) #for APA printing of statistics\nlibrary(lmerTest) #for mixed effects models\nlibrary(here) # for a reproducible workflow\nlibrary(BayesFactor) #for running Bayesian mixed effects models\nlibrary(RSA) #for plotting response surface analyses\nlibrary(lavaan) #for estimating polynomial regression models\nlibrary(AICcmodavg) #for computing AICc values and Akaike weights\nlibrary(gridExtra) #for putting ggplots side by side \nlibrary(broom) # for tidying output of cors\nlibrary(broom.mixed) # for tidying output of MEMs"
  },
  {
    "objectID": "management.html#read-datasets",
    "href": "management.html#read-datasets",
    "title": "5  Management Science",
    "section": "5.2 Read datasets",
    "text": "5.2 Read datasets\n\n# Read composite short data\ncomposites &lt;- read_csv(here(\"data/composites.csv\"))\n\n# Read long data\ndf_long &lt;- read_csv(here(\"data/long_data.csv\"))\n\n#change id and item to factor in preparation for running Bayesian mems\ndf_long$item &lt;- as.factor(df_long$item)\ndf_long$id &lt;- as.factor(df_long$id)\n\n#split data into dfs with self-ratings and other-ratings\nself &lt;- df_long %&gt;% \n  filter(role == \"self\") \n\nothers &lt;- df_long %&gt;% \n  filter(role != \"self\") \n\nmanagers &lt;- others %&gt;% \n  filter(role == \"managers\")\n\ndirect_reports &lt;- others %&gt;% \n  filter(role == \"direct_reports\")\n\npeers &lt;- others %&gt;% \n  filter(role == \"peers\")"
  },
  {
    "objectID": "management.html#response-surface-analysis",
    "href": "management.html#response-surface-analysis",
    "title": "5  Management Science",
    "section": "5.3 Response Surface Analysis",
    "text": "5.3 Response Surface Analysis\nDoes ambition account only for self-views and not for third-party views of leader effectiveness?\nOur first analysis uses Response Surface Analysis to examine how ambition relates to both self-views and third-party views of leader effectiveness. Below, we reproduce the results of the Response Surface Analyses reported in the main paper.\n\nsource(here(\"code/RSA-helper-functions.R\")) #read helper functions\n\n# define initial model set\ninitial_modelset &lt;- c(\n  \"onlyxpos\", # only positive PSV effect model\n  \"xandypos\", # positive main (PSV) effect model\n  \"onlyxneg\", # only negative PSV effect model\n  \"xandyneg\", # negative main (PSV) effect model\n  \"discrpos\", # positive discrepancy (SE) effect model\n  \"discrneg\", # negative discrepancy (SE) effect model\n  \"SQDpos\", # agreement (self-insight) effect model\n  \"SSQDposCneg\", # optimal margin effect model\n  \"onlyypos\", # positive R effect model\n  \"onlyx2pos\", # curvilinear effect of S model\n  \"onlyy2pos\", # curvilinear effect of R model\n  \"IApos\", # positive interaction effect model\n  \"null\", # null model\n  \"full\" # full polynomial model of second degree\n)\n\nRSA_function &lt;- function(z = \"ambition\", df = composites) {\n  #create title for images \n  #depends on if these are the main analyses on the pooled dataset (n = 472)\n  #or the supplemental analyses on the dataset split by wave (n != 472)\n  title &lt;- ifelse(\n    nrow(df)==472, \n    snakecase::to_title_case(z), \n    paste(\"Wave\", unique(df$wave))\n  )\n  #create dataframe\n  dat &lt;- df %&gt;% \n    select(all_of(z), self, others) %&gt;% \n    drop_na()\n  #rename vars for convenience\n  names(dat) &lt;- c(\"z\", \"x\", \"y\")\n  #center the predictor variables on the grand mean of both predictor variables\n  dat &lt;- dat %&gt;% \n    mutate(\n      grand = mean(c(x, y)),\n      x = x - grand,\n      y = y - grand\n    ) %&gt;% \n    select(!grand)\n  \n  # estimate all models\n  out &lt;- eam(\n    variables=names(dat),\n    modelset=initial_modelset, \n    data=dat\n  )\n  \n  # reduce modelset by models which have essentially the same log-likelihood \n  #as simpler models nested within them\n  reduced_set &lt;- initial_modelset[which(!initial_modelset %in% out$toremove)]\n  \n  # Repeat analyses with reduced modelset\n  out_reduced &lt;- eam(\n    variables=names(dat), \n    modelset=reduced_set, \n    data=dat\n  )\n  \n  #Obtain parameter estimates of the best fitting model\n  par &lt;- parameterEstimates(out_reduced$models[[1]])\n  \n  #Plot the best fitting model\n  plot &lt;- plotRSA(\n    b0=par$est[1], #intercept\n    x=par$est[2], #b1 #self\n    y=abs(par$est[3]), #b2 #others #remove minus preceding 0\n    x2=abs(par$est[4]), #b3 #self^2 #remove minus preceding 0\n    xy=abs(par$est[5]), #b4 #interaction #remove minus preceding 0\n    y2=abs(par$est[6]), #b5 #others^2 #remove minus preceding 0\n    main = title,\n    xlab=\"Self-Views\",\n    ylab=\"Third-Party Views\",\n    zlab = snakecase::to_title_case(z),\n    project=helpful_axes_project(out_reduced$coeftab$Modnames[1])$project,\n    coefs = TRUE,\n    axes = \"\"\n  )\n  \n  # show plot\n  print(plot)\n  \n  #Return results for best fitting model\n  out_reduced$aiccoeftab %&gt;%\n    select(Modnames, nicenames, K, AICc, w, b1:b5) %&gt;% \n    slice(1) %&gt;% #only the best fitting model\n    #add important parameters (CI of b1, z and p-value)\n    mutate(\n      b1.lower = par$ci.lower[2], \n      b1.upper = par$ci.upper[2],\n      b1.z = par$z[2],\n      b1.p = par$pvalue[2],\n      measure = z\n    )\n}\n\n# This is the main analysis \nmain &lt;- RSA_function()\n\n\n\n# This is the first robustness check\nr1 &lt;- RSA_function(z = \"motivation_to_lead\")\n\n\n\n#This is the second robustness check\nr2 &lt;- RSA_function(z = \"drive_to_achieve\")\n\n\n\nRSA_results &lt;- rbind(main, r1, r2)\nRSA_results %&gt;% \n  select(measure, w:b1.p) %&gt;% \n  mutate_if(is.numeric, round, digits = 2)\n\n             measure    w   b1 b2 b3 b4 b5 b1.lower b1.upper b1.z b1.p\n1           ambition 0.91 0.28  0  0  0  0     0.14     0.42 3.93    0\n2 motivation_to_lead 0.94 0.48  0  0  0  0     0.27     0.68 4.59    0\n3   drive_to_achieve 0.97 0.22  0  0  0  0     0.11     0.34 3.77    0"
  },
  {
    "objectID": "management.html#correlations",
    "href": "management.html#correlations",
    "title": "5  Management Science",
    "section": "5.4 Correlations",
    "text": "5.4 Correlations\nDoes ambition relate to positive self-views of leader effectiveness?\nOur second analysis examines whether ambition is positively associated with self-rated leader effectiveness. Below, we reproduce the associations reported in the main paper.\n\n#Function to report correlations\nreport_cor &lt;- function(x = ambition, y = self, df = composites) {\n  #Pull the independent variable x (default = ambition)\n  x &lt;- pull(df, {{ x }})\n  #Pull the dependent variable y (default = self-rated effectiveness)\n  y &lt;- pull(df, {{ y }})\n  #run correlation\n  out &lt;- cor.test(x, y) #run correlation test\n  tidy(out)\n}\n\n#Calculate results\ncor1 &lt;- report_cor(ambition, self)\ncor2 &lt;- report_cor(motivation_to_lead, self) \ncor3 &lt;- report_cor(drive_to_achieve, self)\ncor4 &lt;- report_cor(ambition, leader_ability)\ncor5 &lt;- report_cor(drive_to_achieve, leader_ability) \n\ncor_results &lt;- tibble(\n  x = c(\n    \"ambition\", \n    \"motivation_to_lead\",\n    \"drive_to_achieve\",\n    \"ambition\",\n    \"drive_to_achieve\"\n    ),\n  y = c(rep(\"self\", 3), rep(\"leader_ability\", 2)),\n  rbind(cor1, cor2, cor3, cor4, cor5)\n) %&gt;% \n  select(x:conf.high)\n\ncor_results\n\n# A tibble: 5 × 8\n  x               y     estimate statistic  p.value parameter conf.low conf.high\n  &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 ambition        self     0.190      4.18 3.53e- 5       466   0.101      0.276\n2 motivation_to_… self     0.306      4.28 3.10e- 5       177   0.167      0.433\n3 drive_to_achie… self     0.209      3.61 3.68e- 4       285   0.0954     0.317\n4 ambition        lead…    0.169      2.91 3.90e- 3       287   0.0550     0.279\n5 drive_to_achie… lead…    0.424      7.94 4.74e-14       287   0.325      0.514"
  },
  {
    "objectID": "management.html#frequentist-mixed-effects-models",
    "href": "management.html#frequentist-mixed-effects-models",
    "title": "5  Management Science",
    "section": "5.5 Frequentist Mixed Effects Models",
    "text": "5.5 Frequentist Mixed Effects Models\nDoes ambition have a null relationship with third-party perceptions of leader effectiveness?\nOur final analysis examines whether ambition is uncalibrated to third-party leadership evaluations. To assess whether ambition has a null relationship with third-party ratings of leader effectiveness, we first ran a frequentist mixed effects model predicting third-party ratings of effectiveness from ambition (while including random intercepts for leaders and survey items). Below, we reproduce the results reported in the main paper.\n\n# Function to report results of MEM\nreport_mem &lt;- function(Rater = \"others\", x = ambition, y = effectiveness, Wave = 1:2){\n  #Use the correct dataframe: self/other-rated effectiveness\n  if(Rater == \"self\") {dat &lt;- self}\n  if(Rater != \"self\") {dat &lt;- others}\n  #Filter for the correct wave\n  dat &lt;- dat %&gt;% filter(wave %in% Wave)\n  #Filter for a specific rater role if specified, otherwise model will be run\n  # across all other or self ratings\n  if(!Rater %in% c(\"self\", \"others\")) {\n    dat &lt;- dat %&gt;% \n      filter(role == Rater)\n  }\n  #Pull the independent variable x (default = ambition)\n  x &lt;- pull(dat, {{ x }})\n  #Pull the dependent variable y (default = effectiveness)\n  y &lt;- pull(dat, {{ y }})\n  #Run mem \n  fit &lt;- lmer(y ~ x + (1 | id) + (1 | item), data = dat)\n  #Return result in tibble \n  tibble(\n    rater = Rater, tidy(fit) %&gt;% filter(term == \"x\")\n  ) %&gt;% \n    select(rater, estimate:p.value)\n}\n\n# Main result\nmain &lt;- report_mem()\n# First robustness check\nr1 &lt;- report_mem(x = motivation_to_lead)\n# Second robustness check\nr2 &lt;- report_mem(x = drive_to_achieve)\n\ntibble(\n  x = c(\"ambition\", \"motivation_to_lead\", \"drive_to_achieve\"),\n  rbind(main, r1, r2) \n)\n\n# A tibble: 3 × 7\n  x                  rater  estimate std.error statistic    df p.value\n  &lt;chr&gt;              &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 ambition           others   0.0237    0.0225     1.05   464.  0.293 \n2 motivation_to_lead others   0.0116    0.0346     0.335  175.  0.738 \n3 drive_to_achieve   others   0.0684    0.0387     1.77   285.  0.0781"
  },
  {
    "objectID": "management.html#equivalence-tests",
    "href": "management.html#equivalence-tests",
    "title": "5  Management Science",
    "section": "5.6 Equivalence tests",
    "text": "5.6 Equivalence tests\nDoes ambition have a null relationship with third-party perceptions of leader effectiveness?\nSecond, we accompany the preliminary frequentist test with an equivalence test using the two one-sided tests procedure (TOST, Lakens et al. 2018). Below, we reproduce the results reported in the main paper.\n\n# Frequentist equivalence tests for other-ratings\n\n# Equivalence bounds\nbound_u &lt;-  0.15  # Upper equivalence bound\nbound_l &lt;- -0.15  # Lower equivalence bound\n\nrun_eq &lt;- function(df = others, x = ambition, Wave = 1:2) {\n  #Filter for the correct wave\n  df &lt;- df %&gt;% filter(wave %in% Wave)\n  \n  #Pull the independent variable x (default = ambition)\n  x &lt;- pull(df, {{ x }})\n  \n  # Fit model\n  m1 &lt;- lmer(effectiveness ~ x + (1 | id) + (1 | item), data = df)\n  \n  #we can use the contest1D functions of the lmerTest package to perform tests \n  #centered on the lower and upper equivalence bound, using the rhs option\n  \n  # get t value for test against lower bound\n  lower &lt;- contest1D(m1, c(0, 1), confint=TRUE, rhs=bound_l) \n  # get t value for test against upper bound\n  upper &lt;- contest1D(m1, c(0, 1), confint=TRUE, rhs=bound_u) \n  # get dataframe with results for lower and upper bound\n  tibble(\n    df = rep(lower$df) %&gt;% round(2),\n    t = c(lower$`t value`, upper$`t value`) %&gt;% round(2),\n    #The test provided by contest1D is two-sided, divide p-value by 2\n    p = c(lower$`Pr(&gt;|t|)`/2, upper$`Pr(&gt;|t|)`/2) %&gt;% round(3)\n    #If both these tests are significant, so is the test for equivalence\n  ) %&gt;% \n    mutate(\n      p = ifelse(p &lt; .001, \"&lt; .001\", paste(\"=\", gsub(\"0\\\\.\", \".\", p))),\n      bound = c(\"lower\", \"upper\"),\n      result = paste0(\"t(\", df, \") = \", t, \", p \", p)\n    ) %&gt;% \n    select(bound, result)\n}\n# Main result\nmain &lt;- run_eq() %&gt;% mutate(x = \"ambition\")\n# First robustness check\nr1 &lt;- run_eq(x = motivation_to_lead) %&gt;% mutate(x = \"motivation_to_lead\")\n# Second robustness check\nr2 &lt;- run_eq(x = drive_to_achieve) %&gt;% mutate(x = \"drive_to_achieve\")\n\nbind_rows(main, r1, r2) %&gt;% \n  select(x, bound, result)\n\n# A tibble: 6 × 3\n  x                  bound result                     \n  &lt;chr&gt;              &lt;chr&gt; &lt;chr&gt;                      \n1 ambition           lower t(464.2) = 7.72, p &lt; .001  \n2 ambition           upper t(464.2) = -5.61, p &lt; .001 \n3 motivation_to_lead lower t(175.2) = 4.67, p &lt; .001  \n4 motivation_to_lead upper t(175.2) = -4, p &lt; .001    \n5 drive_to_achieve   lower t(284.65) = 5.64, p &lt; .001 \n6 drive_to_achieve   upper t(284.65) = -2.11, p = .018"
  },
  {
    "objectID": "management.html#bayes-factors",
    "href": "management.html#bayes-factors",
    "title": "5  Management Science",
    "section": "5.7 Bayes Factors",
    "text": "5.7 Bayes Factors\nDoes ambition have a null relationship with third-party perceptions of leader effectiveness?\nOur final test uses Bayesian statistics to evaluate the support in favor of the null hypothesis. We calculate Bayes Factors that compare the support for two mixed effects models: a full model (effectiveness ratings predicted from ambition and a random intercept for leader and survey item) versus a null model (effectiveness ratings predicted from a random intercept for leader and survey item).\nBelow, we reproduce the Bayes Factors reported in the main paper (see Table 1). Note that the analysis below takes a while to run. The reader can simply refer to the html document automatically generated from the code, to see the results. Alternatively, run the code in an R script to speed things up.\n\n# Bayesian tests \nget_BF &lt;- function(prior = \"medium\", df = others, x = ambition, Wave = 1:2) {\n  #Filter for the correct wave\n  df &lt;- df %&gt;% filter(wave %in% Wave)\n  #Pull the independent variable x (default = ambition)\n  df$x &lt;- pull(df, {{ x }})\n  \n  #lmBF() does not accept missing values in x\n  df &lt;- df %&gt;% \n    filter(!is.na(x))\n  \n  set.seed(1512)\n  #Run full model\n  full_BF &lt;- lmBF(\n    effectiveness ~ x + id + item, \n    data = df, whichRandom = c('id', 'item'),\n    rscaleCont = prior\n  )\n  set.seed(1512)\n  #Run null model\n  null_BF &lt;- lmBF(\n    effectiveness ~ id + item,\n    data = df, whichRandom = c('id', 'item'),\n    rscaleCont = prior\n  )\n  #Return Bayes Factor in favor of the null\n  as.vector(null_BF / full_BF)  \n}\n\nr_values &lt;- c(\"medium\", \"wide\", \"ultrawide\")\n\n# Other-rated effectiveness\nothers_BF &lt;- sapply(r_values, get_BF)\n# Manager-rated effectiveness\nmanagers_BF &lt;- sapply(r_values, get_BF, df = managers)\n# Peer-rated effectiveness\npeers_BF &lt;- sapply(r_values, get_BF, df = peers)\n# Subordinate-rated effectiveness\ndirect_reports_BF &lt;- sapply(r_values, get_BF, df = direct_reports)\n\n# Main result\nBF_main &lt;- tibble(\n  x = rep(\"Ambition\"),\n  Rater = rep(c(\"Others\", \"Managers\", \"Peers\", \"Direct_Reports\"), each = 3),\n  Prior = rep(r_values, 4),\n  BF = c(others_BF, managers_BF, peers_BF, direct_reports_BF) %&gt;% round(2)\n)\n\nBF_main %&gt;% \n  pivot_wider(\n    names_from = Prior,\n    values_from = BF\n    )\n\n# A tibble: 4 × 5\n  x        Rater          medium  wide ultrawide\n  &lt;chr&gt;    &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 Ambition Others          16.4  23.1      32.6 \n2 Ambition Managers        12.5  17.7      25.0 \n3 Ambition Peers           15.0  21.2      29.9 \n4 Ambition Direct_Reports   1.91  2.67      3.76\n\n\n\n# First robustness check\n\n# Other-rated effectiveness\nothers_r1 &lt;- sapply(r_values, get_BF, x = motivation_to_lead)\n# Manager-rated effectiveness\nmanagers_r1 &lt;- sapply(r_values, get_BF, df = managers, x = motivation_to_lead)\n# Peer-rated effectiveness\npeers_r1 &lt;- sapply(r_values, get_BF, df = peers, x = motivation_to_lead)\n# Subordinate-rated effectiveness\ndirect_reports_r1 &lt;- sapply(r_values, get_BF, df = direct_reports, x = motivation_to_lead)\n\nBF_motivation &lt;- tibble(\n  x = rep(\"Motivation to Lead\"),\n  Rater = rep(c(\"Others\", \"Managers\", \"Peers\", \"Direct_Reports\"), each = 3),\n  Prior = rep(r_values, 4),\n  BF = c(others_r1, managers_r1, peers_r1, direct_reports_r1) %&gt;% round(2)\n)\n\nBF_motivation %&gt;% \n  pivot_wider(\n    names_from = Prior,\n    values_from = BF\n    )\n\n# A tibble: 4 × 5\n  x                  Rater          medium  wide ultrawide\n  &lt;chr&gt;              &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 Motivation to Lead Others          17.1   24.1      34.0\n2 Motivation to Lead Managers         9.51  13.4      18.8\n3 Motivation to Lead Peers           10.3   14.5      20.4\n4 Motivation to Lead Direct_Reports   7.77  10.9      15.3\n\n\n\n# Second robustness check\n\n# Other-rated effectiveness\nothers_r2 &lt;- sapply(r_values, get_BF, x = drive_to_achieve)\n# Manager-rated effectiveness\nmanagers_r2 &lt;- sapply(r_values, get_BF, df = managers, x = drive_to_achieve)\n# Peer-rated effectiveness\npeers_r2 &lt;- sapply(r_values, get_BF, df = peers, x = drive_to_achieve)\n# Subordinate-rated effectiveness\ndirect_reports_r2 &lt;- sapply(r_values, get_BF, df = direct_reports, x = drive_to_achieve)\n\nBF_drive &lt;- tibble(\n  x = rep(\"Drive to Achieve\"),\n  Rater = rep(c(\"Others\", \"Managers\", \"Peers\", \"Direct_Reports\"), each = 3),\n  Prior = rep(r_values, 4),\n  BF = c(others_r2, managers_r2, peers_r2, direct_reports_r2) %&gt;% round(2)\n)\n\nBF_drive %&gt;% \n  pivot_wider(\n    names_from = Prior,\n    values_from = BF\n    )\n\n# A tibble: 4 × 5\n  x                Rater          medium  wide ultrawide\n  &lt;chr&gt;            &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 Drive to Achieve Others           4.81  6.77      9.54\n2 Drive to Achieve Managers         5.16  7.23     10.2 \n3 Drive to Achieve Peers           15.6  21.9      31.0 \n4 Drive to Achieve Direct_Reports   6.05  8.48     12.0"
  },
  {
    "objectID": "score-political.html#set-up",
    "href": "score-political.html#set-up",
    "title": "1  SCORE Political Science",
    "section": "1.1 Set up",
    "text": "1.1 Set up\n\n# Install necessary R packages\ninstall.packages(\"here\") #for a project-based workflow\ninstall.packages(\"haven\")  #to read dta (Stata) file into R\ninstall.packages(\"tidyverse\") #for data processing\ninstall.packages(\"broom\") #for tidying the output of models\nremotes::install_github(\"crsh/papaja\") # for reporting of results\n\n\n# Load R packages\nlibrary(here) \nlibrary(haven)\nlibrary(tidyverse) \nlibrary(papaja)\nlibrary(broom)"
  }
]